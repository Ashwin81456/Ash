{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ashwin81456/Ash/blob/master/updating.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pwwbhMy0pssx"
      },
      "outputs": [],
      "source": [
        "#import the required libraries\n",
        "import os\n",
        "import time\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "\n",
        "#for feature extraction\n",
        "from scipy.signal import welch\n",
        "from scipy.integrate import simps\n",
        "\n",
        "#classifier libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "import xgboost as xgb\n",
        "\n",
        "from sklearn import model_selection\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import itertools\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_recall_curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7ZUAXilSp_n9"
      },
      "outputs": [],
      "source": [
        "def read_data(filename):\n",
        "    x = pickle._Unpickler(open(filename, 'rb'))\n",
        "    x.encoding = 'latin1'\n",
        "    p = x.load()\n",
        "    return p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYK5hgFMqFNy",
        "outputId": "9b8168e5-5fa8-4c2d-9086-5681ea06f7b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['s01.dat', 's02.dat', 's03.dat', 's04.dat', 's05.dat', 's06.dat', 's07.dat', 's08.dat', 's09.dat', 's10.dat', 's11.dat', 's12.dat', 's13.dat', 's14.dat', 's15.dat', 's16.dat', 's17.dat', 's18.dat', 's19.dat', 's20.dat', 's21.dat', 's22.dat', 's23.dat', 's24.dat', 's25.dat', 's26.dat', 's27.dat', 's28.dat', 's29.dat', 's30.dat', 's31.dat', 's32.dat']\n"
          ]
        }
      ],
      "source": [
        "#creating the file names of the dataset to load it\n",
        "files = []\n",
        "for n in range (1, 33):\n",
        "    s = 's'\n",
        "    if n < 10:\n",
        "        s += '0'\n",
        "    s += str(n)\n",
        "    s+=str(\".dat\")\n",
        "    files.append(s)\n",
        "print(files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ru2cxT3qrtI",
        "outputId": "850894fe-b6f0-4d91-ee8c-ac77f7f71588"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# 32x40 = 1280 trials for 32 participants\n",
        "labels = []\n",
        "data = []\n",
        "drive.mount('/content/drive')\n",
        "for i in files:\n",
        "  filename = \"/content/drive/My Drive/MajorProject/Dataset/\" + i\n",
        "  trial = read_data(filename)\n",
        "  labels.append(trial['labels'])\n",
        "  data.append(trial['data'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwIUirXzuY_3",
        "outputId": "3174a586-9299-4ce6-d8ba-924f10465d85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels:  (32, 40, 4)\n",
            "Data:  (32, 40, 40, 8064)\n"
          ]
        }
      ],
      "source": [
        "# Lets see the shapes of the raw data\n",
        "labels = np.array(labels)\n",
        "data = np.array(data)\n",
        "print(\"Labels: \", labels.shape) # participants x videos x labels\n",
        "print(\"Data: \", data.shape) # participants x videos x channels x data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6JhtYReeudzh"
      },
      "outputs": [],
      "source": [
        "# Re-shape arrays into desired shapes\n",
        "labels = labels.flatten()\n",
        "labels = labels.reshape(1280, 4)\n",
        "\n",
        "data = data.flatten()\n",
        "data = data.reshape(1280, 40, 8064)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pw4kk4WasX14",
        "outputId": "0f39bd7c-808e-42ad-e870-cde520d13a97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels:  (1280, 4)\n",
            "Data:  (1280, 40, 8064)\n"
          ]
        }
      ],
      "source": [
        "# Double-check the new arrays\n",
        "#Here trial = participants x vidoes = 32 x 40 = 1280\n",
        "\n",
        "print(\"Labels: \", labels.shape) # trial x label\n",
        "print(\"Data: \", data.shape) # trial x channel x data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 630
        },
        "id": "puNQxQcOx0Gq",
        "outputId": "9118d5a2-651f-4e83-babf-1805f45521bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "printing the labels dataframe\n",
            "\n",
            "         0     1     2     3\n",
            "0     7.71  7.60  6.90  7.83\n",
            "1     8.10  7.31  7.28  8.47\n",
            "2     8.58  7.54  9.00  7.08\n",
            "3     4.94  6.01  6.12  8.06\n",
            "4     6.96  3.92  7.19  6.05\n",
            "...    ...   ...   ...   ...\n",
            "1275  3.91  6.96  5.82  3.12\n",
            "1276  2.81  6.13  6.06  1.04\n",
            "1277  3.05  7.01  5.10  1.10\n",
            "1278  3.99  7.17  4.85  1.00\n",
            "1279  7.15  4.03  9.00  1.88\n",
            "\n",
            "[1280 rows x 4 columns]\n",
            "\n",
            "\n",
            "Describing the labels dataframe\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 0            1            2            3\n",
              "count  1280.000000  1280.000000  1280.000000  1280.000000\n",
              "mean      5.254313     5.156711     5.382750     5.518133\n",
              "std       2.130816     2.020499     2.096321     2.282780\n",
              "min       1.000000     1.000000     1.000000     1.000000\n",
              "25%       3.867500     3.762500     3.932500     3.960000\n",
              "50%       5.040000     5.230000     5.240000     6.050000\n",
              "75%       7.050000     6.950000     7.040000     7.090000\n",
              "max       9.000000     9.000000     9.000000     9.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-59f69423-3a47-4856-924d-7d78bcbbf098\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1280.000000</td>\n",
              "      <td>1280.000000</td>\n",
              "      <td>1280.000000</td>\n",
              "      <td>1280.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5.254313</td>\n",
              "      <td>5.156711</td>\n",
              "      <td>5.382750</td>\n",
              "      <td>5.518133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.130816</td>\n",
              "      <td>2.020499</td>\n",
              "      <td>2.096321</td>\n",
              "      <td>2.282780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3.867500</td>\n",
              "      <td>3.762500</td>\n",
              "      <td>3.932500</td>\n",
              "      <td>3.960000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.040000</td>\n",
              "      <td>5.230000</td>\n",
              "      <td>5.240000</td>\n",
              "      <td>6.050000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>7.050000</td>\n",
              "      <td>6.950000</td>\n",
              "      <td>7.040000</td>\n",
              "      <td>7.090000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-59f69423-3a47-4856-924d-7d78bcbbf098')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-59f69423-3a47-4856-924d-7d78bcbbf098 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-59f69423-3a47-4856-924d-7d78bcbbf098');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0c9fa33e-5ec9-487b-9046-2995cca5ae5b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0c9fa33e-5ec9-487b-9046-2995cca5ae5b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0c9fa33e-5ec9-487b-9046-2995cca5ae5b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"labelsDf\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 450.87147400594165,\n        \"min\": 1.0,\n        \"max\": 1280.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          5.2543125,\n          5.04,\n          1280.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 450.88279505775586,\n        \"min\": 1.0,\n        \"max\": 1280.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          5.1567109375,\n          5.23,\n          1280.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 450.85389766830843,\n        \"min\": 1.0,\n        \"max\": 1280.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          5.38275,\n          5.24,\n          1280.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 3,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 450.79289858765816,\n        \"min\": 1.0,\n        \"max\": 1280.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          5.5181328125,\n          6.05,\n          1280.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "#creating the dataframes for the labels\n",
        "labelsDf = pd.DataFrame(labels)\n",
        "print(\"printing the labels dataframe\\n\")\n",
        "print(labelsDf)\n",
        "print(\"\\n\\nDescribing the labels dataframe\")\n",
        "labelsDf.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SGS2ghM3uYC",
        "outputId": "da97a5af-ba33-48d4-d09b-9800b2de2976"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 0            1            2            3\n",
            "count  1280.000000  1280.000000  1280.000000  1280.000000\n",
            "mean      5.254313     5.156711     5.382750     5.518133\n",
            "std       2.130816     2.020499     2.096321     2.282780\n",
            "min       1.000000     1.000000     1.000000     1.000000\n",
            "25%       3.867500     3.762500     3.932500     3.960000\n",
            "50%       5.040000     5.230000     5.240000     6.050000\n",
            "75%       7.050000     6.950000     7.040000     7.090000\n",
            "max       9.000000     9.000000     9.000000     9.000000\n"
          ]
        }
      ],
      "source": [
        "#giving names to the label columns\n",
        "df_labels= pd.DataFrame({'valence': labels[:,0], 'arousal': labels[:,1], 'dominance': labels[:,2], 'liking': labels[:,3]})\n",
        "print(labelsDf.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3boVQ1FE4var",
        "outputId": "6b0955f9-b567-4a5a-9f1f-8e84a68533b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      valence  arousal\n",
            "0        7.71     7.60\n",
            "1        8.10     7.31\n",
            "2        8.58     7.54\n",
            "3        4.94     6.01\n",
            "4        6.96     3.92\n",
            "...       ...      ...\n",
            "1275     3.91     6.96\n",
            "1276     2.81     6.13\n",
            "1277     3.05     7.01\n",
            "1278     3.99     7.17\n",
            "1279     7.15     4.03\n",
            "\n",
            "[1280 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "#Dropping the Dominance and Liking columns\n",
        "df_labels=df_labels.drop('dominance',axis=1)\n",
        "df_labels=df_labels.drop('liking',axis=1)\n",
        "# print(df_labels.describe())\n",
        "print(df_labels)\n",
        "# df = df.drop('B', axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pet3Pska6SDA"
      },
      "source": [
        "# Separte Valence and Arousal to HAHV, LAHV, HALV, LALV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhIWzOBq6QSq",
        "outputId": "5775df57-5c49-4596-f627-445d29524939"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.23\n",
            "5.04\n",
            "      HAHV  LAHV  HALV  LALV\n",
            "0        1     0     0     0\n",
            "1        1     0     0     0\n",
            "2        1     0     0     0\n",
            "3        0     0     1     0\n",
            "4        0     1     0     0\n",
            "...    ...   ...   ...   ...\n",
            "1275     0     0     1     0\n",
            "1276     0     0     1     0\n",
            "1277     0     0     1     0\n",
            "1278     0     0     1     0\n",
            "1279     0     1     0     0\n",
            "\n",
            "[1280 rows x 4 columns]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# # Create a sample DataFrame with 'valence' and 'arousal' columns\n",
        "# np.random.seed(0)\n",
        "# valence = np.random.uniform(1, 9, 1280)\n",
        "# arousal = np.random.uniform(1, 9, 1280)\n",
        "# data = {'valence': valence, 'arousal': arousal}\n",
        "# df_valence_arousal = pd.DataFrame(data)\n",
        "\n",
        "# Calculate the median value of arousal and valence column\n",
        "arousal_median = df_labels['arousal'].median()\n",
        "print(arousal_median)\n",
        "valence_median = df_labels['valence'].median()\n",
        "print(valence_median)\n",
        "\n",
        "# Create a new DataFrame with the desired columns\n",
        "df_result = pd.DataFrame(index=range(1280), columns=['HAHV', 'LAHV', 'HALV', 'LALV'])\n",
        "df_result[['HAHV', 'LAHV', 'HALV', 'LALV']] = 0\n",
        "\n",
        "# Apply the conditions\n",
        "df_result.loc[(df_labels['valence'] >= valence_median) & (df_labels['arousal'] >= arousal_median), 'HAHV'] = 1\n",
        "df_result.loc[(df_labels['arousal'] < arousal_median) & (df_labels['valence'] >= valence_median), 'LAHV'] = 1\n",
        "df_result.loc[(df_labels['arousal'] >= arousal_median) & (df_labels['valence'] < valence_median), 'HALV'] = 1\n",
        "df_result.loc[(df_labels['valence'] < valence_median) & (df_labels['arousal'] < arousal_median), 'LALV'] = 1\n",
        "\n",
        "# Show the first few rows of the result DataFrame\n",
        "# df_result.tail()\n",
        "print(df_result)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# High Arousal Positive Valence dataset\n",
        "df_hahv = df_labels[(df_labels['valence'] >= np.median(labels[:,0])) & (df_labels['arousal'] >= np.median(labels[:,1]))]\n",
        "# Low Arousal Positive Valence dataset\n",
        "df_lahv = df_labels[(df_labels['valence'] >= np.median(labels[:,0])) & (df_labels['arousal'] < np.median(labels[:,1]))]\n",
        "# High Arousal Negative Valence dataset\n",
        "df_halv = df_labels[(df_labels['valence'] < np.median(labels[:,0])) & (df_labels['arousal'] >= np.median(labels[:,1]))]\n",
        "# Low Arousal Negative Valence dataset\n",
        "df_lalv = df_labels[(df_labels['valence'] < np.median(labels[:,0])) & (df_labels['arousal'] < np.median(labels[:,1]))]"
      ],
      "metadata": {
        "id": "B_fazp2i2KE8"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get mean and std of each group\n",
        "print(\"HAHV\")\n",
        "print(\"Valence:\", \"Mean\", np.round(df_hahv['valence'].mean(),2), \"STD\", np.round(df_hahv['valence'].std(),2))\n",
        "print(\"Arousal:\", \"Mean\", np.round(df_hahv['arousal'].mean(),2), \"STD\", np.round(df_hahv['arousal'].std(),2))\n",
        "print()\n",
        "print(\"LAHV:\")\n",
        "print(\"Valence:\", \"Mean\", np.round(df_lahv['valence'].mean(),2), \"STD\", np.round(df_lahv['valence'].std(),2))\n",
        "print(\"Arousal:\", \"Mean\", np.round(df_lahv['arousal'].mean(),2), \"STD\", np.round(df_lahv['arousal'].std(),2))\n",
        "print()\n",
        "print(\"HALV:\")\n",
        "print(\"Valence:\", \"Mean\", np.round(df_halv['valence'].mean(),2), \"STD\", np.round(df_halv['valence'].std(),2))\n",
        "print(\"Arousal:\", \"Mean\", np.round(df_halv['arousal'].mean(),2), \"STD\", np.round(df_halv['arousal'].std(),2))\n",
        "print()\n",
        "print(\"LALV:\")\n",
        "print(\"Valence:\", \"Mean\", np.round(df_lalv['valence'].mean(),2), \"STD\", np.round(df_lalv['valence'].std(),2))\n",
        "print(\"Arousal:\", \"Mean\", np.round(df_lalv['arousal'].mean(),2), \"STD\", np.round(df_lalv['arousal'].std(),2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yA4yA5xY24qq",
        "outputId": "43731a3c-e065-427b-ee81-a8c6d808c370"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HAHV\n",
            "Valence: Mean 7.23 STD 1.03\n",
            "Arousal: Mean 6.87 STD 0.87\n",
            "\n",
            "LAHV:\n",
            "Valence: Mean 6.59 STD 1.1\n",
            "Arousal: Mean 3.83 STD 1.17\n",
            "\n",
            "HALV:\n",
            "Valence: Mean 3.11 STD 1.25\n",
            "Arousal: Mean 6.8 STD 0.97\n",
            "\n",
            "LALV:\n",
            "Valence: Mean 3.59 STD 1.19\n",
            "Arousal: Mean 3.12 STD 1.32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcYaudZZDylG"
      },
      "source": [
        "Verify the data in 4 classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tc9aAzbD7U3",
        "outputId": "bf72d3f4-ff80-4de9-f3c1-bd3788f2a502"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of 1s in HAHV: 358\n",
            "Number of 1s in LAHV: 322\n",
            "Number of 1s in HALV: 282\n",
            "Number of 1s in LALV: 318\n",
            "Total = 1280\n"
          ]
        }
      ],
      "source": [
        "# Check the number of 1s in each individual column\n",
        "count_HAHV = df_result['HAHV'].sum()\n",
        "count_LAHV = df_result['LAHV'].sum()\n",
        "count_HALV = df_result['HALV'].sum()\n",
        "count_LALV = df_result['LALV'].sum()\n",
        "\n",
        "print(f\"Number of 1s in HAHV: {count_HAHV}\")\n",
        "print(f\"Number of 1s in LAHV: {count_LAHV}\")\n",
        "print(f\"Number of 1s in HALV: {count_HALV}\")\n",
        "print(f\"Number of 1s in LALV: {count_LALV}\")\n",
        "\n",
        "print(f\"Total = {count_HAHV+count_LAHV+count_HALV+count_LALV}\") # the total must be 1280\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#whisker plot of HAHV, LALV, HALV AND LAHV\n",
        "# Valence and Arousal ratings between groups\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(12,4))\n",
        "boxprops = dict(linewidth=2, color='black')\n",
        "whiskerprops = dict(linewidth=2, color='black')\n",
        "capprops = dict(linewidth=2, color='orange')\n",
        "medianprops = dict(linewidth=2, color='red')\n",
        "flierprops = dict(marker='o', color='brown', alpha=0.5)\n",
        "\n",
        "axs[0].set_title(\"Valence\")\n",
        "axs[0].set_ylim(1, 9)\n",
        "axs[0].boxplot([df_hahv['valence'], df_lahv['valence'], df_halv['valence'], df_lalv['valence']], labels=['HAHV','LAHV','HALV', 'LALV'],boxprops=boxprops,\n",
        "               whiskerprops=whiskerprops,\n",
        "               capprops=capprops,\n",
        "               medianprops=medianprops,\n",
        "               flierprops=flierprops)\n",
        "\n",
        "axs[1].set_title(\"Arousal\")\n",
        "axs[1].set_ylim(1, 9)\n",
        "axs[1].boxplot([df_hahv['arousal'], df_lahv['arousal'], df_halv['arousal'], df_lalv['arousal']], labels=['HAHV','LAHV','HALV', 'LALV'],boxprops=boxprops,\n",
        "               whiskerprops=whiskerprops,\n",
        "               capprops=capprops,\n",
        "               medianprops=medianprops,\n",
        "               flierprops=flierprops)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 894
        },
        "id": "HXI6kLgn3PlX",
        "outputId": "17ea60c8-df12-4b42-e0aa-931a327feccc"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'whiskers': [<matplotlib.lines.Line2D at 0x7e9aad8cd360>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aad8cd600>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aad8ce5c0>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aad8ce860>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aad8cf820>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aad8cfac0>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aad90cac0>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aad90cd60>],\n",
              " 'caps': [<matplotlib.lines.Line2D at 0x7e9aad8cd8a0>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aad8cdb40>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aad8ceb00>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aad8ceda0>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aad8cfd60>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aad90c040>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aad90d000>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aad90d2a0>],\n",
              " 'boxes': [<matplotlib.lines.Line2D at 0x7e9aad8cd0c0>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aad8ce320>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aad8cf580>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aad90c820>],\n",
              " 'medians': [<matplotlib.lines.Line2D at 0x7e9aad8cdde0>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aad8cf040>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aad90c2e0>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aad90d570>],\n",
              " 'fliers': [<matplotlib.lines.Line2D at 0x7e9aad8ce080>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aad8cf2e0>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aad90c580>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aad90d840>],\n",
              " 'means': []}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Valence and Arousal ratings per group\n",
        "fig, axs = plt.subplots(2, 2, figsize=(12,8))\n",
        "\n",
        "axs[0,0].set_title(\"HAHV\")\n",
        "axs[0,0].set_ylim(1, 9)\n",
        "axs[0,0].boxplot([df_hahv['valence'], df_hahv['arousal']], labels=['Valence','Arousal'],boxprops=boxprops,\n",
        "               whiskerprops=whiskerprops,\n",
        "               capprops=capprops,\n",
        "               medianprops=medianprops,\n",
        "               flierprops=flierprops)\n",
        "\n",
        "axs[0,1].set_title(\"LAHV\")\n",
        "axs[0,1].set_ylim(1, 9)\n",
        "axs[0,1].boxplot([df_lahv['valence'], df_lahv['arousal']], labels=['Valence','Arousal'],boxprops=boxprops,\n",
        "               whiskerprops=whiskerprops,\n",
        "               capprops=capprops,\n",
        "               medianprops=medianprops,\n",
        "               flierprops=flierprops)\n",
        "\n",
        "axs[1,0].set_title(\"HALV\")\n",
        "axs[1,0].set_ylim(1, 9)\n",
        "axs[1,0].boxplot([df_halv['valence'], df_halv['arousal']], labels=['Valence','Arousal'],boxprops=boxprops,\n",
        "               whiskerprops=whiskerprops,\n",
        "               capprops=capprops,\n",
        "               medianprops=medianprops,\n",
        "               flierprops=flierprops)\n",
        "\n",
        "axs[1,1].set_title(\"LALV\")\n",
        "axs[1,1].set_ylim(1, 9)\n",
        "axs[1,1].boxplot([df_lalv['valence'], df_lalv['arousal']], labels=['Valence','Arousal'],boxprops=boxprops,\n",
        "               whiskerprops=whiskerprops,\n",
        "               capprops=capprops,\n",
        "               medianprops=medianprops,\n",
        "               flierprops=flierprops)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 959
        },
        "id": "ZW2mrFGi5M54",
        "outputId": "5f44eb31-3d72-4799-ec1e-0e83cdbe265e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'whiskers': [<matplotlib.lines.Line2D at 0x7e9aadb61a50>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aadb610c0>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aada54640>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aada550f0>],\n",
              " 'caps': [<matplotlib.lines.Line2D at 0x7e9aada817b0>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aada81510>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aada56a40>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aada57490>],\n",
              " 'boxes': [<matplotlib.lines.Line2D at 0x7e9aadb612a0>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aada83d30>],\n",
              " 'medians': [<matplotlib.lines.Line2D at 0x7e9aada82860>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aada57ee0>],\n",
              " 'fliers': [<matplotlib.lines.Line2D at 0x7e9aada832e0>,\n",
              "  <matplotlib.lines.Line2D at 0x7e9aada55c00>],\n",
              " 'means': []}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Pjhzu_pQlWDv"
      },
      "outputs": [],
      "source": [
        "# Dataset with only Valence column\n",
        "df_val = df_labels['valence']\n",
        "# Dataset with only Arousal column\n",
        "df_aro = df_labels['arousal']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "u8H4KOWLll-C"
      },
      "outputs": [],
      "source": [
        "# Function to check if each trial has positive or negative valence\n",
        "def positive_valence(trial):\n",
        "    return 1 if labels[trial,0] >= np.median(labels[:,0]) else 0\n",
        "# Function to check if each trial has high or low arousal\n",
        "def high_arousal(trial):\n",
        "    return 1 if labels[trial,1] >= np.median(labels[:,1]) else 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37Gsz-Z_lp_2",
        "outputId": "d8861170-843a-434f-a936-401671a247f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       High Valence  High Arousal\n",
            "count   1280.000000   1280.000000\n",
            "mean       0.531250      0.500000\n",
            "std        0.499218      0.500195\n",
            "min        0.000000      0.000000\n",
            "25%        0.000000      0.000000\n",
            "50%        1.000000      0.500000\n",
            "75%        1.000000      1.000000\n",
            "max        1.000000      1.000000\n",
            "      High Valence  High Arousal\n",
            "0                1             1\n",
            "1                1             1\n",
            "2                1             1\n",
            "3                0             1\n",
            "4                1             0\n",
            "...            ...           ...\n",
            "1275             0             1\n",
            "1276             0             1\n",
            "1277             0             1\n",
            "1278             0             1\n",
            "1279             1             0\n",
            "\n",
            "[1280 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "# Convert all ratings to boolean values\n",
        "labels_encoded = []\n",
        "for i in range (len(labels)):\n",
        "    labels_encoded.append([positive_valence(i), high_arousal(i)])\n",
        "labels_encoded = np.reshape(labels_encoded, (1280, 2))\n",
        "df_labels = pd.DataFrame(data=labels_encoded, columns=[\"High Valence\", \"High Arousal\"])\n",
        "print(df_labels.describe())\n",
        "print(df_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BrMAjqult5R",
        "outputId": "457e6fd2-2cb2-49a6-e32a-cec79f139d56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0       1\n",
            "1       1\n",
            "2       1\n",
            "3       0\n",
            "4       1\n",
            "       ..\n",
            "1275    0\n",
            "1276    0\n",
            "1277    0\n",
            "1278    0\n",
            "1279    1\n",
            "Name: High Valence, Length: 1280, dtype: int64\n",
            "(1280,)\n"
          ]
        }
      ],
      "source": [
        "# Dataset with only Valence column\n",
        "df_valence = df_labels['High Valence']\n",
        "# Dataset with only Arousal column\n",
        "df_arousal = df_labels['High Arousal']\n",
        "print(df_valence)\n",
        "print(df_valence.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gh0IevZcnKtX"
      },
      "source": [
        "# FEATURE EXTRACTION USING WELCH'S METHOD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "QGtC7nRipvA8"
      },
      "outputs": [],
      "source": [
        "eeg_channels = np.array([\"Fp1\", \"AF3\", \"F3\", \"F7\", \"FC5\", \"FC1\", \"C3\", \"T7\", \"CP5\", \"CP1\", \"P3\", \"P7\", \"PO3\", \"O1\", \"Oz\", \"Pz\", \"Fp2\", \"AF4\", \"Fz\", \"F4\", \"F8\", \"FC6\", \"FC2\", \"Cz\", \"C4\", \"T8\", \"CP6\", \"CP2\", \"P4\", \"P8\", \"PO4\", \"O2\"])\n",
        "peripheral_channels = np.array([\"hEOG\", \"vEOG\", \"zEMG\", \"tEMG\", \"GSR\", \"Respiration belt\", \"Plethysmograph\", \"Temperature\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyC_7IWLp93t",
        "outputId": "62e20c55-1e45-424c-9f68-c2d270048200"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1280, 32, 8064)\n"
          ]
        }
      ],
      "source": [
        "eeg_data = []\n",
        "for i in range (len(data)):\n",
        "  for j in range (len(eeg_channels)):\n",
        "    eeg_data.append(data[i,j])\n",
        "eeg_data = np.reshape(eeg_data, (len(data), len(eeg_channels), len(data[0,0])))\n",
        "print(eeg_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5P3G0PWqEsM",
        "outputId": "ded95c09-07e5-4bf1-ca73-ca372be4c718"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1280, 8, 8064)\n"
          ]
        }
      ],
      "source": [
        "peripheral_data = []\n",
        "for i in range (len(data)):\n",
        "  for j in range (32,len(data[0])):\n",
        "    peripheral_data.append(data[i,j])\n",
        "peripheral_data = np.reshape(peripheral_data, (len(data), len(peripheral_channels), len(data[0,0])))\n",
        "print(peripheral_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "sns.set(font_scale=1.2)\n",
        "\n",
        "# Define sampling frequency and time vector\n",
        "sf = 128.\n",
        "time = np.arange(eeg_data.size) / sf\n",
        "\n",
        "# Plot the signal of first trial, last channel\n",
        "fig, ax = plt.subplots(1, 1, figsize=(16, 4))\n",
        "plt.plot(eeg_data[0,31], lw=1.1, color='red')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Voltage')\n",
        "sns.despine()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "niBZLGCf6QKm",
        "outputId": "a3351ec5-20b3-43f0-d9e8-9167171e0007"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Xc9rTRGHnYKt"
      },
      "outputs": [],
      "source": [
        "def bandpower(data, sf, band, window_sec=None, relative=False):\n",
        "    band = np.asarray(band)\n",
        "    low, high = band\n",
        "\n",
        "    # Define window length\n",
        "    if window_sec is not None:\n",
        "        nperseg = window_sec * sf\n",
        "    else:\n",
        "        nperseg = (2 / low) * sf\n",
        "\n",
        "    # Compute the modified periodogram (Welch)\n",
        "    freqs, psd = welch(data, sf, nperseg=nperseg)\n",
        "\n",
        "    # Frequency resolution\n",
        "    freq_res = freqs[1] - freqs[0]\n",
        "\n",
        "    # Find closest indices of band in frequency vector\n",
        "    idx_band = np.logical_and(freqs >= low, freqs <= high)\n",
        "\n",
        "    # Integral approximation of the spectrum using Simpson's rule.\n",
        "    bp = simps(psd[idx_band], dx=freq_res)\n",
        "\n",
        "    if relative:\n",
        "        bp /= simps(psd, dx=freq_res)\n",
        "    return bp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "mIxttAuQnrel"
      },
      "outputs": [],
      "source": [
        "def get_band_power(trial, channel, band):\n",
        "  bd = (0,0)\n",
        "\n",
        "  if (band == \"theta\"): # drownsiness, emotional connection, intuition, creativity\n",
        "    bd = (4,8)\n",
        "  elif (band == \"alpha\"): # reflection, relaxation\n",
        "    bd = (8,12)\n",
        "  elif (band == \"beta\"): # concentration, problem solving, memory\n",
        "    bd = (12,30)\n",
        "  elif (band == \"gamma\"): # cognition, perception, learning, multi-tasking\n",
        "    bd = (30,64)\n",
        "\n",
        "  return bandpower(eeg_data[trial,channel], 128, bd)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpNyS4s8n9Q3",
        "outputId": "5507975d-1a55-4873-8c24-5b23941e5010"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.434119660168186\n",
            "5.369595513295193\n",
            "6.286556266834863\n",
            "0.9879159580139809\n"
          ]
        }
      ],
      "source": [
        "print(get_band_power(0,31,\"theta\"))\n",
        "print(get_band_power(0,31,\"alpha\"))\n",
        "print(get_band_power(0,31,\"beta\"))\n",
        "print(get_band_power(0,31,\"gamma\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8psQHMB9xqpj"
      },
      "source": [
        "# Process new datasets with 6 EEG regions and 4 band power values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0y_hNHIxoxi"
      },
      "outputs": [],
      "source": [
        "# Transform 1280x 32 x 8064 => 1280 x 128\n",
        "eeg_band_arr = []\n",
        "for i in range (len(eeg_data)):\n",
        "  for j in range (len(eeg_data[0])):\n",
        "    eeg_band_arr.append(get_band_power(i,j,\"theta\"))\n",
        "    eeg_band_arr.append(get_band_power(i,j,\"alpha\"))\n",
        "    eeg_band_arr.append(get_band_power(i,j,\"beta\"))\n",
        "    eeg_band_arr.append(get_band_power(i,j,\"gamma\"))\n",
        "eeg_band_arr = np.reshape(eeg_band_arr, (1280, 128))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVksA4V2ypUD"
      },
      "outputs": [],
      "source": [
        "frontal = np.array([\"F3\", \"FC1\", \"Fz\", \"F4\", \"FC2\"])\n",
        "parietal = np.array([\"P3\", \"P7\", \"Pz\", \"P4\", \"P8\"])\n",
        "occipital = np.array([\"O1\", \"Oz\", \"O2\", \"PO3\", \"PO4\"])\n",
        "central = np.array([\"CP5\", \"CP1\", \"Cz\", \"C4\", \"C3\", \"CP6\", \"CP2\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YQbtKTRzmdG",
        "outputId": "f627f7a9-6457-4201-9af0-397af79b7023"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                Fp1           AF3            F3            F7           FC5  \\\n",
            "count   1280.000000   1280.000000   1280.000000   1280.000000   1280.000000   \n",
            "mean     517.431002    974.493856    795.093910   1515.004071    746.435950   \n",
            "std     1165.295163   3147.555132   3020.711666   4990.544508   2188.101734   \n",
            "min        2.698928      1.995398      1.820656      3.283107      1.311200   \n",
            "25%       23.306027     17.117475     18.392335     30.827191     14.023436   \n",
            "50%       65.468048     82.102529     60.241953     91.266539     48.704968   \n",
            "75%      331.636624    304.949248    175.394835    248.308696    218.358248   \n",
            "max    15524.135098  38122.870846  39431.320394  49272.793208  20182.668545   \n",
            "\n",
            "               FC1            C3           T7           CP5          CP1  ...  \\\n",
            "count  1280.000000   1280.000000  1280.000000   1280.000000  1280.000000  ...   \n",
            "mean    345.936665    486.095113   354.004358    664.656754   276.667812  ...   \n",
            "std     717.328768   1497.636647   641.432373   2146.857585   498.823733  ...   \n",
            "min       2.025214      1.200156     3.418167      1.857737     1.340340  ...   \n",
            "25%      17.383454     18.273844    43.838157     19.178089    28.281757  ...   \n",
            "50%      55.561232     46.451432   128.629588     61.998792    60.330974  ...   \n",
            "75%     281.828747    234.342275   348.249862    312.653366   237.040645  ...   \n",
            "max    8542.244175  26021.167025  7023.985761  23255.512271  5972.589469  ...   \n",
            "\n",
            "                FC2            Cz            C4            T8           CP6  \\\n",
            "count   1280.000000   1280.000000   1280.000000   1280.000000   1280.000000   \n",
            "mean     669.953166    518.975872    471.905917    763.990397    544.785103   \n",
            "std     1714.340609   1407.210210   1896.584105   2236.655420   1563.878765   \n",
            "min        2.809501      1.637028      1.713283      2.133474      1.496299   \n",
            "25%       14.927239     23.440039      9.724978     25.143155     18.202863   \n",
            "50%       66.078472     67.044674     24.318235     90.110040     77.517763   \n",
            "75%      214.293557    305.766182    109.715681    386.232875    297.742897   \n",
            "max    18617.218099  16408.471958  24826.365142  28038.714329  19908.437378   \n",
            "\n",
            "               CP2            P4           P8           PO4            O2  \n",
            "count  1280.000000   1280.000000  1280.000000   1280.000000   1280.000000  \n",
            "mean    303.158814    527.491149   222.759444    780.700914    327.242856  \n",
            "std     650.093432   1429.084909   451.119818   1802.083002   1080.707954  \n",
            "min       1.439077      1.791296     1.641482      1.995230      3.681268  \n",
            "25%      26.754006     18.110041    18.064264     23.491991     19.333926  \n",
            "50%      88.083088     62.269206    90.914662     69.772647     49.630345  \n",
            "75%     257.959593    246.195582   225.463786    495.202699    113.117403  \n",
            "max    7210.746793  17568.065100  5487.311705  17167.017710  12314.030522  \n",
            "\n",
            "[8 rows x 32 columns]\n"
          ]
        }
      ],
      "source": [
        "eeg_theta = []\n",
        "for i in range (len(eeg_data)):\n",
        "  for j in range (len(eeg_data[0])):\n",
        "    eeg_theta.append(get_band_power(i,j,\"theta\"))\n",
        "eeg_theta = np.reshape(eeg_theta, (1280, 32))\n",
        "\n",
        "df_theta = pd.DataFrame(data = eeg_theta, columns=eeg_channels)\n",
        "print(df_theta.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1uT6ZlnzqL-",
        "outputId": "6027237f-1bc1-41c5-94f4-0bd96c53ef1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               Fp1           AF3            F3            F7          FC5  \\\n",
            "count  1280.000000   1280.000000   1280.000000   1280.000000  1280.000000   \n",
            "mean    173.544174    333.184883    285.545436    573.725974   249.793720   \n",
            "std     378.371554   1058.758333   1036.330438   1943.692827   702.436934   \n",
            "min       2.770151      1.793012      1.724442      2.793554     0.975527   \n",
            "25%      14.082681     10.737435     10.012318     15.888935    10.074042   \n",
            "50%      33.713172     34.992442     30.026795     38.178299    20.079100   \n",
            "75%     125.508396    114.334883     73.488279     93.987498    74.040939   \n",
            "max    5627.906982  12380.702125  12764.724842  20843.070851  6575.781434   \n",
            "\n",
            "               FC1           C3           T7          CP5          CP1  ...  \\\n",
            "count  1280.000000  1280.000000  1280.000000  1280.000000  1280.000000  ...   \n",
            "mean    138.011594   170.423962   124.101183   232.750895    97.610644  ...   \n",
            "std     275.218934   497.507620   200.171342   735.717912   166.430024  ...   \n",
            "min       1.682977     1.963403     2.545447     2.251935     1.682386  ...   \n",
            "25%       9.228670    10.197058    21.452775    11.461012    13.367379  ...   \n",
            "50%      24.929907    22.318468    51.473641    25.364340    26.229818  ...   \n",
            "75%     117.988147    83.518174   129.890552   110.822931    91.941255  ...   \n",
            "max    3030.077791  9215.549575  2142.437275  7894.273428  2148.109415  ...   \n",
            "\n",
            "               FC2           Cz            C4           T8          CP6  \\\n",
            "count  1280.000000  1280.000000   1280.000000  1280.000000  1280.000000   \n",
            "mean    228.331178   199.941306    193.380344   276.638039   213.620700   \n",
            "std     569.202821   578.947819    812.031964   782.782127   661.135030   \n",
            "min       2.390011     1.315395      1.227024     1.636114     2.181082   \n",
            "25%       8.715210    12.127290      6.665166    15.980086    11.300805   \n",
            "50%      26.880000    29.827367     14.169702    34.252038    31.722499   \n",
            "75%      95.964685   102.480314     40.800135   142.704220   106.673844   \n",
            "max    6038.451512  6881.486185  10501.570698  9022.269308  8394.200372   \n",
            "\n",
            "               CP2           P4           P8          PO4           O2  \n",
            "count  1280.000000  1280.000000  1280.000000  1280.000000  1280.000000  \n",
            "mean    112.138023   181.507936    89.003586   269.572920   126.053116  \n",
            "std     236.260122   482.163785   186.841170   597.330120   400.465505  \n",
            "min       1.520363     2.158950     1.212432     2.002769     3.617116  \n",
            "25%      15.797490    11.564300    10.971965    13.489443    10.548845  \n",
            "50%      37.807211    28.494994    38.758864    29.247807    23.906708  \n",
            "75%      86.070815    92.261617    88.107272   162.117585    45.294454  \n",
            "max    2368.537880  5666.733316  2323.499853  5542.263376  3966.714864  \n",
            "\n",
            "[8 rows x 32 columns]\n"
          ]
        }
      ],
      "source": [
        "# Transform 880 x 32 x 8064 => 880 x 32\n",
        "eeg_alpha = []\n",
        "for i in range (len(eeg_data)):\n",
        "  for j in range (len(eeg_data[0])):\n",
        "    eeg_alpha.append(get_band_power(i,j,\"alpha\"))\n",
        "eeg_alpha = np.reshape(eeg_alpha, (1280, 32))\n",
        "\n",
        "df_alpha = pd.DataFrame(data = eeg_alpha, columns=eeg_channels)\n",
        "print(df_alpha.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUNGxdRLzvAW",
        "outputId": "836e7504-40b3-4382-860a-eb28db8c9e0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               Fp1          AF3           F3            F7          FC5  \\\n",
            "count  1280.000000  1280.000000  1280.000000   1280.000000  1280.000000   \n",
            "mean     92.200266   200.684361   193.372441    341.951096   140.642394   \n",
            "std     176.162562   668.027842   668.771074   1274.679748   386.740178   \n",
            "min       4.486703     2.650970     2.784376      3.363422     2.788531   \n",
            "25%      17.999409    13.190613    10.170223     17.951892    11.341571   \n",
            "50%      34.413828    29.155242    28.120517     33.617573    22.402198   \n",
            "75%      80.774739   107.619088    59.807546     62.087123    53.162211   \n",
            "max    3528.485435  5784.160193  5841.475721  14848.700463  3094.687504   \n",
            "\n",
            "               FC1           C3           T7          CP5          CP1  ...  \\\n",
            "count  1280.000000  1280.000000  1280.000000  1280.000000  1280.000000  ...   \n",
            "mean     99.397187    96.901859    77.540922   137.387625    55.047411  ...   \n",
            "std     197.556641   247.621839    90.107877   409.366974    85.846400  ...   \n",
            "min       3.145262     2.991550     2.477519     2.886994     2.237445  ...   \n",
            "25%       8.919796     9.331138    23.668656    11.097811     9.370318  ...   \n",
            "50%      17.625226    19.698019    44.350493    22.622621    18.748879  ...   \n",
            "75%      79.066898    46.494215    93.087474    58.273844    51.308093  ...   \n",
            "max    1702.542675  5187.441594   634.645675  4094.116788  1238.024108  ...   \n",
            "\n",
            "               FC2           Cz           C4           T8          CP6  \\\n",
            "count  1280.000000  1280.000000  1280.000000  1280.000000  1280.000000   \n",
            "mean    130.756212   131.961699   136.536661   178.534190   144.021213   \n",
            "std     338.843374   409.481195   603.902680   506.405387   484.806320   \n",
            "min       3.037555     1.816169     2.079646     2.429178     2.524762   \n",
            "25%       9.115906    10.803851     7.350435    17.466794    11.400277   \n",
            "50%      17.479204    25.300435    12.926731    30.157902    23.679679   \n",
            "75%      75.259937    54.745901    25.609433    93.320360    64.338413   \n",
            "max    2786.622358  4842.537927  7489.480637  4064.418656  5955.637009   \n",
            "\n",
            "               CP2           P4           P8          PO4           O2  \n",
            "count  1280.000000  1280.000000  1280.000000  1280.000000  1280.000000  \n",
            "mean     74.751315   103.971557    62.850280   148.868580    90.837375  \n",
            "std     165.803855   288.941591   134.177873   329.650542   275.150372  \n",
            "min       2.272088     2.914214     3.059450     2.461123     5.084168  \n",
            "25%      13.014515    11.560334    12.312069    13.732279    11.291516  \n",
            "50%      24.705624    20.439224    27.763129    23.940855    19.688820  \n",
            "75%      53.062550    67.593128    64.187473    99.947093    36.076683  \n",
            "max    1265.234960  2533.794744  1653.743590  2516.334382  2454.759737  \n",
            "\n",
            "[8 rows x 32 columns]\n"
          ]
        }
      ],
      "source": [
        "# Transform 880 x 32 x 8064 => 880 x 32\n",
        "eeg_beta = []\n",
        "for i in range (len(eeg_data)):\n",
        "  for j in range (len(eeg_data[0])):\n",
        "    eeg_beta.append(get_band_power(i,j,\"beta\"))\n",
        "eeg_beta = np.reshape(eeg_beta, (1280, 32))\n",
        "\n",
        "df_beta = pd.DataFrame(data = eeg_beta, columns=eeg_channels)\n",
        "print(df_beta.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJP58i-60AEV",
        "outputId": "4e551a91-ced0-420c-ca45-5e40b606fc96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               Fp1          AF3           F3           F7          FC5  \\\n",
            "count  1280.000000  1280.000000  1280.000000  1280.000000  1280.000000   \n",
            "mean     50.663247   150.492372   149.210824   122.775294    91.633571   \n",
            "std     135.591365   645.635199   632.049548   496.744509   340.562025   \n",
            "min       1.069233     1.119910     0.791859     1.177512     0.712624   \n",
            "25%       8.292302     5.605668     4.352724     7.591098     5.172920   \n",
            "50%      18.329100    14.069330    11.828027    15.919877    12.648067   \n",
            "75%      39.995543    43.454610    28.586812    36.456420    38.094737   \n",
            "max    3213.255538  6060.539788  5758.756812  6348.177208  3472.515858   \n",
            "\n",
            "               FC1           C3           T7          CP5          CP1  ...  \\\n",
            "count  1280.000000  1280.000000  1280.000000  1280.000000  1280.000000  ...   \n",
            "mean     60.487715    56.236468    43.792285    77.048369    29.250057  ...   \n",
            "std     139.230040   180.285647    62.089299   267.809883    68.503827  ...   \n",
            "min       0.694928     0.684210     0.562676     0.788359     0.509259  ...   \n",
            "25%       2.666459     3.534375    10.492723     3.837095     3.156311  ...   \n",
            "50%       5.313502     9.056340    23.540152     9.532963     7.735783  ...   \n",
            "75%      41.027482    29.838450    54.382720    22.302862    18.604669  ...   \n",
            "max    1413.985901  4376.356658   809.935644  2294.561961  1011.985310  ...   \n",
            "\n",
            "               FC2           Cz           C4           T8          CP6  \\\n",
            "count  1280.000000  1280.000000  1280.000000  1280.000000  1280.000000   \n",
            "mean     79.191679    56.547283    55.989289   117.745424    64.340498   \n",
            "std     306.464243   167.968314   239.143748   428.381018   199.387966   \n",
            "min       0.692350     0.395680     0.697486     1.027260     0.609425   \n",
            "25%       2.893590     3.800780     2.286229     7.221083     3.850387   \n",
            "50%       7.535055     8.493068     4.640151    17.921722    10.563661   \n",
            "75%      26.896601    20.882885    13.538524    39.981006    30.943717   \n",
            "max    2829.052404  1892.813293  3054.309237  3954.519861  2405.614840   \n",
            "\n",
            "               CP2           P4           P8          PO4           O2  \n",
            "count  1280.000000  1280.000000  1280.000000  1280.000000  1280.000000  \n",
            "mean     46.943309    68.100629    29.805883    82.197819    55.821892  \n",
            "std     142.501802   265.168885    57.843154   272.880509   203.288109  \n",
            "min       0.478152     0.761387     0.804002     0.838747     0.877576  \n",
            "25%       3.849956     3.690054     4.513405     4.620006     4.380690  \n",
            "50%       8.646393     7.300040    10.911662    10.430337     6.994829  \n",
            "75%      22.614200    28.908609    26.489674    42.960182    14.567389  \n",
            "max    1426.462453  2446.765512   647.533599  2505.826127  1794.801694  \n",
            "\n",
            "[8 rows x 32 columns]\n"
          ]
        }
      ],
      "source": [
        "# Transform 880 x 32 x 8064 => 880 x 32\n",
        "eeg_gamma = []\n",
        "for i in range (len(eeg_data)):\n",
        "  for j in range (len(eeg_data[0])):\n",
        "    eeg_gamma.append(get_band_power(i,j,\"gamma\"))\n",
        "eeg_gamma = np.reshape(eeg_gamma, (1280, 32))\n",
        "\n",
        "df_gamma = pd.DataFrame(data = eeg_gamma, columns=eeg_channels)\n",
        "print(df_gamma.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmTpi6Qc02Bu"
      },
      "outputs": [],
      "source": [
        "# Split the data into training/testing sets\n",
        "def split_train_test(x, y):\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)\n",
        "  return x_train, x_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOCvaWDba3pa"
      },
      "outputs": [],
      "source": [
        "# Feature scaling\n",
        "def feature_scaling(train, test):\n",
        "  sc = StandardScaler()\n",
        "  train = sc.fit_transform(train)\n",
        "  test = sc.transform(test)\n",
        "  return train, test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHrmKN1nf8ys"
      },
      "outputs": [],
      "source": [
        "band_names = np.array([\"theta\", \"alpha\", \"beta\", \"gamma\"])\n",
        "channel_names = np.array([\"frontal\",  \"central\", \"parietal\", \"occipital\"])\n",
        "label_names = np.array([\"valence\", \"arousal\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYVZwPvFgATk"
      },
      "outputs": [],
      "source": [
        "# Testing different kernels (linear, sigmoid, rbf, poly) to select the most optimal one\n",
        "clf_svm = SVC(kernel = 'rbf',random_state = 42, probability=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4pznSOZgHmK"
      },
      "outputs": [],
      "source": [
        "# Testing different k (odd) numbers, algorithm (auto, ball_tree, kd_tree) and weight (uniform, distance) to select the most optimal one\n",
        "clf_knn = KNeighborsClassifier(n_neighbors=5, weights='distance', algorithm='auto')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gi_aMFOgL08"
      },
      "outputs": [],
      "source": [
        "clf_dtree=DecisionTreeClassifier(max_depth=20,min_samples_split=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9hH4fktgPOX"
      },
      "outputs": [],
      "source": [
        "clf_rf=RandomForestClassifier(n_estimators=50,max_depth=20,min_samples_split=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lJ9wwn0gUmH"
      },
      "outputs": [],
      "source": [
        "clf_nb= GaussianNB()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-f5ay_0gYey"
      },
      "outputs": [],
      "source": [
        "# Testing different learning rate (alpha), solver (adam, sgd, lbfgs) and activation (relu, tanh, logistic) to select the most optimal one\n",
        "clf_mlp = MLPClassifier(solver='adam', activation='tanh', alpha=0.3, max_iter=400)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOCq_XttoT4e"
      },
      "outputs": [],
      "source": [
        "clf_adaboost = AdaBoostClassifier(n_estimators=50, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJMuk2lWq8v6"
      },
      "outputs": [],
      "source": [
        "clf_xgb = xgb.XGBClassifier(learning_rate=0.1, max_depth=3, n_estimators=100, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KFc0oT1XMHGv"
      },
      "outputs": [],
      "source": [
        "import lightgbm as lgb\n",
        "clf_lgbm = lgb.LGBMClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_SB4HCTNIWQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "clf_gpc = GaussianProcessClassifier(kernel=1.0 * RBF(length_scale=1.0), random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQ_4Dt-2N5t8"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Perceptron\n",
        "clf_perceptron = Perceptron(random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pheOwL8PlYt",
        "outputId": "31aba06f-3fcd-47a5-bba3-6c44ee09ca32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.5-cp310-cp310-manylinux2014_x86_64.whl (98.2 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m98.2/98.2 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.25.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.0.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.11.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.3.0)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.2.5\n"
          ]
        }
      ],
      "source": [
        "!pip install catboost\n",
        "import catboost as cb\n",
        "clf_catboost = cb.CatBoostClassifier(iterations=1000, depth=6, learning_rate=0.1, loss_function='Logloss', verbose=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#define cnn model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Input\n",
        "\n",
        "def create_cnn_model(data_np):\n",
        "    model = Sequential([\n",
        "        Input(shape=(data_np.shape[1], 1)),  # Adjusted to match data_np shape\n",
        "        Conv1D(filters=64, kernel_size=1, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Dropout(0.2),\n",
        "        Conv1D(filters=64, kernel_size=1, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Dropout(0.2),\n",
        "        Flatten(),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.1),\n",
        "        Dense(2, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def train_and_evaluate_cnn(df_x, df_y):\n",
        "    # Convert dataframes to numpy arrays\n",
        "    data_np = df_x.values\n",
        "    labels_np = df_y.values\n",
        "\n",
        "    # Reshape data for CNN: (number of samples, height, width, channels)\n",
        "    # Here, height=1, width=number of features, channels=1\n",
        "    data_reshaped = data_np.reshape((data_np.shape[0], data_np.shape[1], 1))\n",
        "\n",
        "    # One-hot encode the labels\n",
        "    labels_encoded = to_categorical(labels_np)\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(data_reshaped, labels_encoded, test_size=0.20, random_state=42)\n",
        "\n",
        "    # Define the CNN model\n",
        "    model = create_cnn_model(data_np)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "\n",
        "    return test_loss, test_accuracy\n"
      ],
      "metadata": {
        "id": "tIwd_l6MD6dw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define ann model\n",
        "def create_ann_model(data_scaled):\n",
        "    model = Sequential([\n",
        "        Dense(64, input_dim=data_scaled.shape[1], activation='relu'),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(2, activation='softmax')  # Assuming two classes: 0 and 1\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "\n",
        "def train_and_evaluate_ann(df_x, df_y):\n",
        "    # Convert dataframes to numpy arrays\n",
        "    data_np = df_x.values\n",
        "    labels_np = df_y.values\n",
        "\n",
        "    # Standardize the data\n",
        "    scaler = StandardScaler()\n",
        "    data_scaled = scaler.fit_transform(data_np)\n",
        "\n",
        "    # One-hot encode the labels\n",
        "    labels_encoded = to_categorical(labels_np)\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(data_scaled, labels_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Define the CNN model\n",
        "    model = create_ann_model(data_np)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "\n",
        "    return test_loss, test_accuracy"
      ],
      "metadata": {
        "id": "C81EuQgrZIim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define lstm model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "def create_lstm_model(data_np):\n",
        "    model = Sequential([\n",
        "    LSTM(20, input_shape=(data_np.shape[1], 1)),\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(2, activation='softmax')  # Assuming two classes: 0 and 1\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def train_and_evaluate_lstm(df_x, df_y):\n",
        "    # Convert dataframes to numpy arrays\n",
        "    data_np = df_x.values\n",
        "    labels_np = df_y.values\n",
        "\n",
        "    # Reshape data for LSTM: (samples, time_steps, features)\n",
        "    # Here, each row is treated as a sequence with a single time step\n",
        "    data_reshaped = data_np.reshape((data_np.shape[0], data_np.shape[1], 1))\n",
        "\n",
        "    # One-hot encode the labels\n",
        "    labels_encoded = to_categorical(labels_np)\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(data_reshaped, labels_encoded, test_size=0.2, random_state=42)\n",
        "    # Define the CNN model\n",
        "    model = create_lstm_model(data_np)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "    return test_loss, test_accuracy\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7hC14PKCbZUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i28DLITPgfgJ"
      },
      "outputs": [],
      "source": [
        "models = []\n",
        "models.append(('SVM', clf_svm))\n",
        "models.append(('k-NN', clf_knn))\n",
        "models.append(('DT', clf_dtree))\n",
        "models.append(('RF', clf_rf))\n",
        "models.append(('NB', clf_nb))\n",
        "models.append(('MLP', clf_mlp))\n",
        "models.append(('AB', clf_adaboost))\n",
        "models.append(('XGB', clf_xgb))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_WzJMzsjrL4"
      },
      "outputs": [],
      "source": [
        "def run_clf_cv(band, channel, label, clf):\n",
        "  if (band == \"theta\"):\n",
        "    df_x = df_theta\n",
        "  elif (band == \"alpha\"):\n",
        "    df_x = df_alpha\n",
        "  elif (band == \"beta\"):\n",
        "    df_x = df_beta\n",
        "  elif (band == \"gamma\"):\n",
        "    df_x = df_gamma\n",
        "\n",
        "  if (channel == \"frontal\"):\n",
        "    df_x = df_x[frontal]\n",
        "  elif (channel == \"central\"):\n",
        "    df_x = df_x[central]\n",
        "  elif (channel == \"parietal\"):\n",
        "    df_x = df_x[parietal]\n",
        "  elif (channel == \"occipital\"):\n",
        "    df_x = df_x[occipital]\n",
        "\n",
        "  # df_y = df_arousal if (label == \"arousal\") else df_valence\n",
        "  # print(df_y.shape)\n",
        "  # df_y = df_result[\"HAHV\"]\n",
        "  # df_y = df_result\n",
        "  # df_y = df_y.flatten\n",
        "  # print(f\"the shape of df_y is {df_y.shape}\")\n",
        "  # print(f\"the shape of df_x is {df_x.shape}\")\n",
        "  if (label == \"HAHV\"):\n",
        "    df_y = df_result[\"HAHV\"]\n",
        "  elif (label == \"LAHV\"):\n",
        "    df_y = df_result[\"LAHV\"]\n",
        "  elif (label == \"HALV\"):\n",
        "    df_y = df_result[\"HALV\"]\n",
        "  elif (label == \"LALV\"):\n",
        "    df_y = df_result[\"LALV\"]\n",
        "\n",
        "  # print(f\"the shape of df_y is {df_y.shape}\")\n",
        "  # print(f\"the shape of df_x is {df_x.shape}\")\n",
        "  # Train-test split\n",
        "\n",
        "  # save he dataframes in csv format for analysis\n",
        "  # if (band == \"gamma\" and channel == \"frontal\" and label == \"HALV\"):\n",
        "  #   df_y.to_csv('labels.csv', index=False)\n",
        "  #   print(\"DataFrame saved to 'labels.csv'\")\n",
        "  #   df_x.to_csv('data.csv', index=False)\n",
        "  #   print(\"DataFrame saved to 'data.csv'\")\n",
        "  #   from google.colab import files\n",
        "  #   files.download('labels.csv')\n",
        "  #   files.download('data.csv')\n",
        "\n",
        "  x_train, x_test, y_train, y_test = split_train_test(df_x, df_y)\n",
        "\n",
        "  # Apply CV\n",
        "  x_for_kfold = np.array(x_train)\n",
        "  y_for_kfold = np.array(y_train)\n",
        "  kfold = model_selection.KFold(n_splits=5)\n",
        "\n",
        "  for i, j in kfold.split(x_for_kfold):\n",
        "   x_train2, x_test2 = x_for_kfold[i], x_for_kfold[j]\n",
        "   y_train2, y_test2 = y_for_kfold[i], y_for_kfold[j]\n",
        "\n",
        "  # Feature scaling\n",
        "  x_train2, x_test2 = feature_scaling(x_train2, x_test2)\n",
        "\n",
        "  # Feature scaling\n",
        "  # scaler = StandardScaler()\n",
        "  # x_train2 = scaler.fit_transform(x_train2)\n",
        "  # x_test2 = scaler.transform(x_test2)\n",
        "\n",
        "\n",
        "  if (clf == \"svm\"):\n",
        "    clf_svm.fit(x_train2, y_train2)\n",
        "    y_predict = clf_svm.predict(x_test2)\n",
        "  elif (clf == \"knn\"):\n",
        "    clf_knn.fit(x_train2, y_train2)\n",
        "    y_predict = clf_knn.predict(x_test2)\n",
        "  elif (clf == \"dtree\"):\n",
        "    clf_dtree.fit(x_train2, y_train2)\n",
        "    y_predict = clf_dtree.predict(x_test2)\n",
        "  elif (clf == \"rf\"):\n",
        "    clf_rf.fit(x_train2, y_train2)\n",
        "    y_predict = clf_rf.predict(x_test2)\n",
        "  elif (clf == \"nb\"):\n",
        "    clf_nb.fit(x_train2, y_train2)\n",
        "    y_predict = clf_nb.predict(x_test2)\n",
        "  elif (clf == \"mlp\"):\n",
        "    clf_mlp.fit(x_train2, y_train2)\n",
        "    y_predict = clf_mlp.predict(x_test2)\n",
        "  elif (clf == \"ab\"):\n",
        "    clf_adaboost.fit(x_train2, y_train2)\n",
        "    y_predict = clf_adaboost.predict(x_test2)\n",
        "  elif (clf == \"xgb\"):\n",
        "    clf_xgb.fit(x_train2, y_train2)\n",
        "    y_predict = clf_xgb.predict(x_test2)\n",
        "  elif (clf == \"lgbm\"):\n",
        "    clf_lgbm.fit(x_train2, y_train2)\n",
        "    y_predict = clf_lgbm.predict(x_test2)\n",
        "  elif (clf == \"gpc\"):\n",
        "    clf_gpc.fit(x_train2, y_train2)\n",
        "    y_predict = clf_gpc.predict(x_test2)\n",
        "  elif (clf == \"per\"):\n",
        "    clf_perceptron.fit(x_train2, y_train2)\n",
        "    y_predict = clf_perceptron.predict(x_test2)\n",
        "  elif (clf == \"cb\"):\n",
        "    clf_catboost.fit(x_train2, y_train2)\n",
        "    y_predict = clf_catboost.predict(x_test2)\n",
        "  elif (clf == \"cnn\"):\n",
        "    # Evaluate the model on the test set\n",
        "    test_loss, test_accuracy = train_and_evaluate_cnn(df_x, df_y)\n",
        "    # print(f\"Test Loss: {test_loss}\")\n",
        "    # print(f\"Test Accuracy: {test_accuracy}\")\n",
        "    return \"DL\",test_loss, test_accuracy\n",
        "\n",
        "  elif(clf ==\"ann\"):\n",
        "    test_loss, test_accuracy = train_and_evaluate_ann(df_x, df_y)\n",
        "    # print(f\"Test Loss: {test_loss}\")\n",
        "    # print(f\"Test Accuracy: {test_accuracy}\")\n",
        "    return \"DL\",test_loss, test_accuracy\n",
        "  elif(clf ==\"lstm\"):\n",
        "    test_loss, test_accuracy = train_and_evaluate_lstm(df_x, df_y)\n",
        "    return \"DL\",test_loss,test_accuracy\n",
        "  return \"ML\",y_test2, y_predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWN0kvbJjyhB"
      },
      "outputs": [],
      "source": [
        "def get_accuracy(band, channel, label, clf):\n",
        "  classifier,y_test2, y_predict = run_clf_cv(band, channel, label, clf)\n",
        "  if (classifier == \"DL\"):\n",
        "    return y_predict\n",
        "  return np.round(accuracy_score(y_test2, y_predict)*100,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cB-1MOCIuv_M"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "def print_conf(band, channel, label, clf):\n",
        "  y_test2, y_predict = run_clf_cv(band, channel, label, clf)\n",
        "  conf_matrix = confusion_matrix(y_test2, y_predict)\n",
        "  # print(conf_matrix)\n",
        "  plt.figure(figsize=(4, 2))  # Decrease the figure size\n",
        "  plt.title('Confusion Matrix')\n",
        "  sns.heatmap(conf_matrix,\n",
        "              annot=True,\n",
        "              fmt='g',\n",
        "              xticklabels=['Not Spam','Spam'],\n",
        "              yticklabels=['Not Spam','Spam'])\n",
        "\n",
        "  # display matrix\n",
        "  plt.ylabel('Actual',fontsize=12)\n",
        "  plt.xlabel('Prediction',fontsize=12)\n",
        "  plt.show()\n",
        "\n",
        "  # printing the classification report aswell\n",
        "\n",
        "  class_report = classification_report(y_test2, y_predict, target_names=['Not Spam', 'Spam'])\n",
        "  print(\"\\nClassification Report:\")\n",
        "  print(class_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kBo9bznkFa9"
      },
      "outputs": [],
      "source": [
        "def print_accuracy(label, clf):\n",
        "  arr = []\n",
        "  for i in range (len(band_names)):\n",
        "    for j in range (len(channel_names)):\n",
        "      arr.append(get_accuracy(band_names[i], channel_names[j], label, clf))\n",
        "  arr = np.reshape(arr, (4,4))\n",
        "  df = pd.DataFrame(data = arr, index=band_names, columns=channel_names)\n",
        "\n",
        "  #print(\"Top 3 EEG regions with highest scores\")\n",
        "  #print(df.apply(lambda s: s.abs()).max().nlargest(3))\n",
        "  #print()\n",
        "  #print(\"Top 2 bands with highest scores\")\n",
        "  #print(df.apply(lambda s: s.abs()).max(axis=1).nlargest(2))\n",
        "  #print()\n",
        "  #print(\"EEG region with highest scores per each band\")\n",
        "  #print(df.idxmax(axis=1))\n",
        "  #print()\n",
        "  #print(\"Accuracy Scores\")\n",
        "  #print(df.idxmax())\n",
        "  #print()\n",
        "  print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDIaK777kOdU",
        "outputId": "48234377-d1c5-4bbe-d3f4-cad467c7bfb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       frontal  central  parietal  occipital\n",
            "theta    68.63    69.61     69.12      68.63\n",
            "alpha    68.63    70.10     69.12      68.63\n",
            "beta     70.10    69.61     70.10      70.10\n",
            "gamma    69.61    69.61     70.10      69.61\n"
          ]
        }
      ],
      "source": [
        "print_accuracy('HAHV', 'svm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RfE3GdBoXXlK"
      },
      "outputs": [],
      "source": [
        "print_conf(\"beta\",\"frontal\",\"HAHV\",\"svm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTqPyKdifUch"
      },
      "outputs": [],
      "source": [
        "print_accuracy('LAHV', 'svm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bv-yHWWNXq4F"
      },
      "outputs": [],
      "source": [
        "print_conf(\"theta\",\"occipital\",\"LAHV\",\"svm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BaV8Ul3zfbVG"
      },
      "outputs": [],
      "source": [
        "print_accuracy('HALV', 'svm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsXUXB_mX4Yq"
      },
      "outputs": [],
      "source": [
        "print_conf(\"gamma\",\"frontal\",\"HALV\",\"svm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8sPz6Kjdfkia"
      },
      "outputs": [],
      "source": [
        "print_accuracy('LALV', 'svm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IytKfnprYIKG"
      },
      "outputs": [],
      "source": [
        "print_conf(\"gamma\",\"occipital\",\"LALV\",\"svm\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"LALV\",\"ann\")"
      ],
      "metadata": {
        "id": "3ZJ1eRTBagJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy(\"HALV\",\"lstm\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47cLDLLtc3dL",
        "outputId": "571393d7-9b6a-4fb9-cb5a-12f15bc17912"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "32/32 [==============================] - 9s 67ms/step - loss: 0.6641 - accuracy: 0.6357 - val_loss: 0.5201 - val_accuracy: 0.7930\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5913 - accuracy: 0.7529 - val_loss: 0.5151 - val_accuracy: 0.7930\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5653 - accuracy: 0.7559 - val_loss: 0.5125 - val_accuracy: 0.7930\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5797 - accuracy: 0.7656 - val_loss: 0.5179 - val_accuracy: 0.7930\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5664 - accuracy: 0.7686 - val_loss: 0.5146 - val_accuracy: 0.7930\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5568 - accuracy: 0.7705 - val_loss: 0.5167 - val_accuracy: 0.7930\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5572 - accuracy: 0.7725 - val_loss: 0.5144 - val_accuracy: 0.7930\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5470 - accuracy: 0.7734 - val_loss: 0.5190 - val_accuracy: 0.7930\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5704 - accuracy: 0.7754 - val_loss: 0.5166 - val_accuracy: 0.7930\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5542 - accuracy: 0.7764 - val_loss: 0.5177 - val_accuracy: 0.7930\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5475 - accuracy: 0.7764 - val_loss: 0.5187 - val_accuracy: 0.7930\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5431 - accuracy: 0.7764 - val_loss: 0.5156 - val_accuracy: 0.7930\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5513 - accuracy: 0.7773 - val_loss: 0.5152 - val_accuracy: 0.7930\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5432 - accuracy: 0.7764 - val_loss: 0.5199 - val_accuracy: 0.7930\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5360 - accuracy: 0.7764 - val_loss: 0.5181 - val_accuracy: 0.7930\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5416 - accuracy: 0.7764 - val_loss: 0.5185 - val_accuracy: 0.7930\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5401 - accuracy: 0.7764 - val_loss: 0.5160 - val_accuracy: 0.7930\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5441 - accuracy: 0.7764 - val_loss: 0.5225 - val_accuracy: 0.7930\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5400 - accuracy: 0.7764 - val_loss: 0.5166 - val_accuracy: 0.7930\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5447 - accuracy: 0.7754 - val_loss: 0.5212 - val_accuracy: 0.7930\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5362 - accuracy: 0.7764 - val_loss: 0.5191 - val_accuracy: 0.7930\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5418 - accuracy: 0.7754 - val_loss: 0.5189 - val_accuracy: 0.7930\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5266 - accuracy: 0.7764 - val_loss: 0.5141 - val_accuracy: 0.7930\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5445 - accuracy: 0.7764 - val_loss: 0.5225 - val_accuracy: 0.7930\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5349 - accuracy: 0.7764 - val_loss: 0.5217 - val_accuracy: 0.7930\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5360 - accuracy: 0.7764 - val_loss: 0.5151 - val_accuracy: 0.7930\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5309 - accuracy: 0.7764 - val_loss: 0.5170 - val_accuracy: 0.7930\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5406 - accuracy: 0.7764 - val_loss: 0.5224 - val_accuracy: 0.7930\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5480 - accuracy: 0.7764 - val_loss: 0.5281 - val_accuracy: 0.7930\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5281 - accuracy: 0.7764 - val_loss: 0.5155 - val_accuracy: 0.7930\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5315 - accuracy: 0.7764 - val_loss: 0.5151 - val_accuracy: 0.7930\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5411 - accuracy: 0.7764 - val_loss: 0.5195 - val_accuracy: 0.7930\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5381 - accuracy: 0.7764 - val_loss: 0.5177 - val_accuracy: 0.7930\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5339 - accuracy: 0.7764 - val_loss: 0.5170 - val_accuracy: 0.7930\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5382 - accuracy: 0.7764 - val_loss: 0.5181 - val_accuracy: 0.7930\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5346 - accuracy: 0.7764 - val_loss: 0.5154 - val_accuracy: 0.7930\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5376 - accuracy: 0.7764 - val_loss: 0.5180 - val_accuracy: 0.7930\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5326 - accuracy: 0.7764 - val_loss: 0.5141 - val_accuracy: 0.7930\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5341 - accuracy: 0.7764 - val_loss: 0.5158 - val_accuracy: 0.7930\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5369 - accuracy: 0.7764 - val_loss: 0.5120 - val_accuracy: 0.7930\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5351 - accuracy: 0.7764 - val_loss: 0.5220 - val_accuracy: 0.7930\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5362 - accuracy: 0.7764 - val_loss: 0.5176 - val_accuracy: 0.7930\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5372 - accuracy: 0.7764 - val_loss: 0.5165 - val_accuracy: 0.7930\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5272 - accuracy: 0.7764 - val_loss: 0.5137 - val_accuracy: 0.7930\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5268 - accuracy: 0.7764 - val_loss: 0.5148 - val_accuracy: 0.7930\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5331 - accuracy: 0.7764 - val_loss: 0.5131 - val_accuracy: 0.7930\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5272 - accuracy: 0.7764 - val_loss: 0.5106 - val_accuracy: 0.7930\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5244 - accuracy: 0.7764 - val_loss: 0.5116 - val_accuracy: 0.7930\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5302 - accuracy: 0.7764 - val_loss: 0.5136 - val_accuracy: 0.7930\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5374 - accuracy: 0.7764 - val_loss: 0.5150 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5150 - accuracy: 0.7930\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 3s 31ms/step - loss: 0.6318 - accuracy: 0.7109 - val_loss: 0.5240 - val_accuracy: 0.7930\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5989 - accuracy: 0.7500 - val_loss: 0.5253 - val_accuracy: 0.7930\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5668 - accuracy: 0.7559 - val_loss: 0.5302 - val_accuracy: 0.7930\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5749 - accuracy: 0.7617 - val_loss: 0.5303 - val_accuracy: 0.7930\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5515 - accuracy: 0.7695 - val_loss: 0.5331 - val_accuracy: 0.7930\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5403 - accuracy: 0.7734 - val_loss: 0.5343 - val_accuracy: 0.7930\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5504 - accuracy: 0.7695 - val_loss: 0.5332 - val_accuracy: 0.7930\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5627 - accuracy: 0.7686 - val_loss: 0.5312 - val_accuracy: 0.7930\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5529 - accuracy: 0.7695 - val_loss: 0.5313 - val_accuracy: 0.7930\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5426 - accuracy: 0.7754 - val_loss: 0.5356 - val_accuracy: 0.7930\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5384 - accuracy: 0.7744 - val_loss: 0.5279 - val_accuracy: 0.7930\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5320 - accuracy: 0.7754 - val_loss: 0.5319 - val_accuracy: 0.7930\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5489 - accuracy: 0.7754 - val_loss: 0.5367 - val_accuracy: 0.7930\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5400 - accuracy: 0.7764 - val_loss: 0.5272 - val_accuracy: 0.7930\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5494 - accuracy: 0.7764 - val_loss: 0.5284 - val_accuracy: 0.7930\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5326 - accuracy: 0.7764 - val_loss: 0.5262 - val_accuracy: 0.7930\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5267 - accuracy: 0.7764 - val_loss: 0.5277 - val_accuracy: 0.7930\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5414 - accuracy: 0.7764 - val_loss: 0.5353 - val_accuracy: 0.7930\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5379 - accuracy: 0.7764 - val_loss: 0.5321 - val_accuracy: 0.7930\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5292 - accuracy: 0.7764 - val_loss: 0.5280 - val_accuracy: 0.7930\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5387 - accuracy: 0.7764 - val_loss: 0.5282 - val_accuracy: 0.7930\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5429 - accuracy: 0.7764 - val_loss: 0.5297 - val_accuracy: 0.7930\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5341 - accuracy: 0.7764 - val_loss: 0.5282 - val_accuracy: 0.7930\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5328 - accuracy: 0.7764 - val_loss: 0.5250 - val_accuracy: 0.7930\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5387 - accuracy: 0.7764 - val_loss: 0.5326 - val_accuracy: 0.7930\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5285 - accuracy: 0.7764 - val_loss: 0.5286 - val_accuracy: 0.7930\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5361 - accuracy: 0.7764 - val_loss: 0.5314 - val_accuracy: 0.7930\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5348 - accuracy: 0.7764 - val_loss: 0.5293 - val_accuracy: 0.7930\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5362 - accuracy: 0.7764 - val_loss: 0.5277 - val_accuracy: 0.7930\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5323 - accuracy: 0.7764 - val_loss: 0.5239 - val_accuracy: 0.7930\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5303 - accuracy: 0.7764 - val_loss: 0.5259 - val_accuracy: 0.7930\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5321 - accuracy: 0.7764 - val_loss: 0.5286 - val_accuracy: 0.7930\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5306 - accuracy: 0.7764 - val_loss: 0.5280 - val_accuracy: 0.7930\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5279 - accuracy: 0.7764 - val_loss: 0.5210 - val_accuracy: 0.7930\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5326 - accuracy: 0.7764 - val_loss: 0.5239 - val_accuracy: 0.7930\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5253 - accuracy: 0.7764 - val_loss: 0.5228 - val_accuracy: 0.7930\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5311 - accuracy: 0.7764 - val_loss: 0.5254 - val_accuracy: 0.7930\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5310 - accuracy: 0.7764 - val_loss: 0.5229 - val_accuracy: 0.7930\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5290 - accuracy: 0.7764 - val_loss: 0.5227 - val_accuracy: 0.7930\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5241 - accuracy: 0.7764 - val_loss: 0.5184 - val_accuracy: 0.7930\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5292 - accuracy: 0.7764 - val_loss: 0.5184 - val_accuracy: 0.7930\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5242 - accuracy: 0.7764 - val_loss: 0.5192 - val_accuracy: 0.7930\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5224 - accuracy: 0.7764 - val_loss: 0.5154 - val_accuracy: 0.7930\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5264 - accuracy: 0.7764 - val_loss: 0.5174 - val_accuracy: 0.7930\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5324 - accuracy: 0.7764 - val_loss: 0.5198 - val_accuracy: 0.7930\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5263 - accuracy: 0.7764 - val_loss: 0.5205 - val_accuracy: 0.7930\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5255 - accuracy: 0.7764 - val_loss: 0.5168 - val_accuracy: 0.7930\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5268 - accuracy: 0.7764 - val_loss: 0.5168 - val_accuracy: 0.7930\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5261 - accuracy: 0.7764 - val_loss: 0.5132 - val_accuracy: 0.7930\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5263 - accuracy: 0.7764 - val_loss: 0.5117 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5117 - accuracy: 0.7930\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 3s 21ms/step - loss: 0.6244 - accuracy: 0.6787 - val_loss: 0.5122 - val_accuracy: 0.7930\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5506 - accuracy: 0.7705 - val_loss: 0.5039 - val_accuracy: 0.7930\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5734 - accuracy: 0.7783 - val_loss: 0.5065 - val_accuracy: 0.7930\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5622 - accuracy: 0.7715 - val_loss: 0.5066 - val_accuracy: 0.7930\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5448 - accuracy: 0.7754 - val_loss: 0.5067 - val_accuracy: 0.7930\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5572 - accuracy: 0.7764 - val_loss: 0.5086 - val_accuracy: 0.7930\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5476 - accuracy: 0.7744 - val_loss: 0.5117 - val_accuracy: 0.7930\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5384 - accuracy: 0.7764 - val_loss: 0.5089 - val_accuracy: 0.7930\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5553 - accuracy: 0.7754 - val_loss: 0.5126 - val_accuracy: 0.7930\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5332 - accuracy: 0.7754 - val_loss: 0.5089 - val_accuracy: 0.7930\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5443 - accuracy: 0.7764 - val_loss: 0.5103 - val_accuracy: 0.7930\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5360 - accuracy: 0.7764 - val_loss: 0.5131 - val_accuracy: 0.7930\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5450 - accuracy: 0.7764 - val_loss: 0.5075 - val_accuracy: 0.7930\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5425 - accuracy: 0.7764 - val_loss: 0.5156 - val_accuracy: 0.7930\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5362 - accuracy: 0.7764 - val_loss: 0.5082 - val_accuracy: 0.7930\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5318 - accuracy: 0.7764 - val_loss: 0.5113 - val_accuracy: 0.7930\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5420 - accuracy: 0.7764 - val_loss: 0.5137 - val_accuracy: 0.7930\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5349 - accuracy: 0.7764 - val_loss: 0.5139 - val_accuracy: 0.7930\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5347 - accuracy: 0.7764 - val_loss: 0.5142 - val_accuracy: 0.7930\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5255 - accuracy: 0.7764 - val_loss: 0.5108 - val_accuracy: 0.7930\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5321 - accuracy: 0.7764 - val_loss: 0.5108 - val_accuracy: 0.7930\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5297 - accuracy: 0.7764 - val_loss: 0.5114 - val_accuracy: 0.7930\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5351 - accuracy: 0.7764 - val_loss: 0.5111 - val_accuracy: 0.7930\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5294 - accuracy: 0.7764 - val_loss: 0.5099 - val_accuracy: 0.7930\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5316 - accuracy: 0.7764 - val_loss: 0.5121 - val_accuracy: 0.7930\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5355 - accuracy: 0.7764 - val_loss: 0.5102 - val_accuracy: 0.7930\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5370 - accuracy: 0.7764 - val_loss: 0.5120 - val_accuracy: 0.7930\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5285 - accuracy: 0.7764 - val_loss: 0.5119 - val_accuracy: 0.7930\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5296 - accuracy: 0.7764 - val_loss: 0.5110 - val_accuracy: 0.7930\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5272 - accuracy: 0.7764 - val_loss: 0.5121 - val_accuracy: 0.7930\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5329 - accuracy: 0.7764 - val_loss: 0.5112 - val_accuracy: 0.7930\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5348 - accuracy: 0.7764 - val_loss: 0.5096 - val_accuracy: 0.7930\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5279 - accuracy: 0.7764 - val_loss: 0.5114 - val_accuracy: 0.7930\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5319 - accuracy: 0.7764 - val_loss: 0.5106 - val_accuracy: 0.7930\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5274 - accuracy: 0.7764 - val_loss: 0.5104 - val_accuracy: 0.7930\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5261 - accuracy: 0.7764 - val_loss: 0.5074 - val_accuracy: 0.7930\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5231 - accuracy: 0.7764 - val_loss: 0.5081 - val_accuracy: 0.7930\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5282 - accuracy: 0.7764 - val_loss: 0.5094 - val_accuracy: 0.7930\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5267 - accuracy: 0.7764 - val_loss: 0.5100 - val_accuracy: 0.7930\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5296 - accuracy: 0.7764 - val_loss: 0.5117 - val_accuracy: 0.7930\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5278 - accuracy: 0.7764 - val_loss: 0.5132 - val_accuracy: 0.7930\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5252 - accuracy: 0.7764 - val_loss: 0.5114 - val_accuracy: 0.7930\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5316 - accuracy: 0.7764 - val_loss: 0.5080 - val_accuracy: 0.7930\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5199 - accuracy: 0.7764 - val_loss: 0.5080 - val_accuracy: 0.7930\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5289 - accuracy: 0.7764 - val_loss: 0.5103 - val_accuracy: 0.7930\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5298 - accuracy: 0.7764 - val_loss: 0.5119 - val_accuracy: 0.7930\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5244 - accuracy: 0.7764 - val_loss: 0.5084 - val_accuracy: 0.7930\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5318 - accuracy: 0.7764 - val_loss: 0.5083 - val_accuracy: 0.7930\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5270 - accuracy: 0.7764 - val_loss: 0.5092 - val_accuracy: 0.7930\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5284 - accuracy: 0.7764 - val_loss: 0.5074 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7930\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 3s 21ms/step - loss: 0.5760 - accuracy: 0.7529 - val_loss: 0.5138 - val_accuracy: 0.7930\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5761 - accuracy: 0.7715 - val_loss: 0.5190 - val_accuracy: 0.7930\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5706 - accuracy: 0.7744 - val_loss: 0.5177 - val_accuracy: 0.7930\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5546 - accuracy: 0.7764 - val_loss: 0.5176 - val_accuracy: 0.7930\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5518 - accuracy: 0.7764 - val_loss: 0.5182 - val_accuracy: 0.7930\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5465 - accuracy: 0.7764 - val_loss: 0.5193 - val_accuracy: 0.7930\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5441 - accuracy: 0.7764 - val_loss: 0.5229 - val_accuracy: 0.7930\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5433 - accuracy: 0.7764 - val_loss: 0.5212 - val_accuracy: 0.7930\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5474 - accuracy: 0.7764 - val_loss: 0.5294 - val_accuracy: 0.7930\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5429 - accuracy: 0.7764 - val_loss: 0.5284 - val_accuracy: 0.7930\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5408 - accuracy: 0.7764 - val_loss: 0.5284 - val_accuracy: 0.7930\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5292 - accuracy: 0.7764 - val_loss: 0.5261 - val_accuracy: 0.7930\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5365 - accuracy: 0.7764 - val_loss: 0.5233 - val_accuracy: 0.7930\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5414 - accuracy: 0.7764 - val_loss: 0.5278 - val_accuracy: 0.7930\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5413 - accuracy: 0.7764 - val_loss: 0.5248 - val_accuracy: 0.7930\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5383 - accuracy: 0.7764 - val_loss: 0.5243 - val_accuracy: 0.7930\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5364 - accuracy: 0.7764 - val_loss: 0.5204 - val_accuracy: 0.7930\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5354 - accuracy: 0.7764 - val_loss: 0.5221 - val_accuracy: 0.7930\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5475 - accuracy: 0.7764 - val_loss: 0.5257 - val_accuracy: 0.7930\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5338 - accuracy: 0.7764 - val_loss: 0.5250 - val_accuracy: 0.7930\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5397 - accuracy: 0.7764 - val_loss: 0.5251 - val_accuracy: 0.7930\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5359 - accuracy: 0.7764 - val_loss: 0.5201 - val_accuracy: 0.7930\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5344 - accuracy: 0.7764 - val_loss: 0.5165 - val_accuracy: 0.7930\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5311 - accuracy: 0.7764 - val_loss: 0.5154 - val_accuracy: 0.7930\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5382 - accuracy: 0.7764 - val_loss: 0.5191 - val_accuracy: 0.7930\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5431 - accuracy: 0.7764 - val_loss: 0.5219 - val_accuracy: 0.7930\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5318 - accuracy: 0.7764 - val_loss: 0.5224 - val_accuracy: 0.7930\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5294 - accuracy: 0.7764 - val_loss: 0.5194 - val_accuracy: 0.7930\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5318 - accuracy: 0.7764 - val_loss: 0.5221 - val_accuracy: 0.7930\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5321 - accuracy: 0.7764 - val_loss: 0.5212 - val_accuracy: 0.7930\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5373 - accuracy: 0.7764 - val_loss: 0.5244 - val_accuracy: 0.7930\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5417 - accuracy: 0.7764 - val_loss: 0.5262 - val_accuracy: 0.7930\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5335 - accuracy: 0.7764 - val_loss: 0.5237 - val_accuracy: 0.7930\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5372 - accuracy: 0.7764 - val_loss: 0.5261 - val_accuracy: 0.7930\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5320 - accuracy: 0.7764 - val_loss: 0.5204 - val_accuracy: 0.7930\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5350 - accuracy: 0.7764 - val_loss: 0.5245 - val_accuracy: 0.7930\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5304 - accuracy: 0.7764 - val_loss: 0.5245 - val_accuracy: 0.7930\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5339 - accuracy: 0.7764 - val_loss: 0.5186 - val_accuracy: 0.7930\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5389 - accuracy: 0.7764 - val_loss: 0.5206 - val_accuracy: 0.7930\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5293 - accuracy: 0.7764 - val_loss: 0.5212 - val_accuracy: 0.7930\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5328 - accuracy: 0.7764 - val_loss: 0.5195 - val_accuracy: 0.7930\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5344 - accuracy: 0.7764 - val_loss: 0.5214 - val_accuracy: 0.7930\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5298 - accuracy: 0.7764 - val_loss: 0.5209 - val_accuracy: 0.7930\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5349 - accuracy: 0.7764 - val_loss: 0.5207 - val_accuracy: 0.7930\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5332 - accuracy: 0.7764 - val_loss: 0.5207 - val_accuracy: 0.7930\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5352 - accuracy: 0.7764 - val_loss: 0.5178 - val_accuracy: 0.7930\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5302 - accuracy: 0.7764 - val_loss: 0.5187 - val_accuracy: 0.7930\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5288 - accuracy: 0.7764 - val_loss: 0.5156 - val_accuracy: 0.7930\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5366 - accuracy: 0.7764 - val_loss: 0.5194 - val_accuracy: 0.7930\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5318 - accuracy: 0.7764 - val_loss: 0.5158 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.7930\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 3s 22ms/step - loss: 0.7580 - accuracy: 0.5088 - val_loss: 0.5274 - val_accuracy: 0.7930\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5878 - accuracy: 0.7568 - val_loss: 0.5122 - val_accuracy: 0.7930\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5836 - accuracy: 0.7568 - val_loss: 0.5111 - val_accuracy: 0.7930\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5706 - accuracy: 0.7783 - val_loss: 0.5131 - val_accuracy: 0.7930\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5629 - accuracy: 0.7725 - val_loss: 0.5149 - val_accuracy: 0.7930\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5536 - accuracy: 0.7725 - val_loss: 0.5095 - val_accuracy: 0.7930\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5522 - accuracy: 0.7666 - val_loss: 0.5092 - val_accuracy: 0.7930\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5533 - accuracy: 0.7686 - val_loss: 0.5087 - val_accuracy: 0.7930\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5475 - accuracy: 0.7734 - val_loss: 0.5070 - val_accuracy: 0.7930\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5360 - accuracy: 0.7773 - val_loss: 0.5056 - val_accuracy: 0.7930\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5430 - accuracy: 0.7754 - val_loss: 0.5080 - val_accuracy: 0.7930\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5427 - accuracy: 0.7754 - val_loss: 0.5082 - val_accuracy: 0.7930\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5329 - accuracy: 0.7764 - val_loss: 0.5082 - val_accuracy: 0.7930\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5433 - accuracy: 0.7754 - val_loss: 0.5084 - val_accuracy: 0.7930\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5291 - accuracy: 0.7764 - val_loss: 0.5057 - val_accuracy: 0.7930\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5272 - accuracy: 0.7764 - val_loss: 0.5034 - val_accuracy: 0.7930\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5411 - accuracy: 0.7744 - val_loss: 0.5023 - val_accuracy: 0.7930\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5351 - accuracy: 0.7754 - val_loss: 0.5042 - val_accuracy: 0.7930\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5365 - accuracy: 0.7754 - val_loss: 0.5029 - val_accuracy: 0.7930\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5374 - accuracy: 0.7754 - val_loss: 0.5021 - val_accuracy: 0.7930\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5329 - accuracy: 0.7764 - val_loss: 0.5012 - val_accuracy: 0.7930\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5332 - accuracy: 0.7764 - val_loss: 0.5025 - val_accuracy: 0.7930\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5385 - accuracy: 0.7764 - val_loss: 0.5094 - val_accuracy: 0.7930\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5239 - accuracy: 0.7764 - val_loss: 0.4991 - val_accuracy: 0.7930\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5355 - accuracy: 0.7764 - val_loss: 0.4993 - val_accuracy: 0.7930\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5252 - accuracy: 0.7764 - val_loss: 0.4987 - val_accuracy: 0.7930\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5271 - accuracy: 0.7764 - val_loss: 0.4993 - val_accuracy: 0.7930\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5341 - accuracy: 0.7764 - val_loss: 0.5019 - val_accuracy: 0.7930\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5290 - accuracy: 0.7754 - val_loss: 0.5022 - val_accuracy: 0.7930\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5285 - accuracy: 0.7764 - val_loss: 0.5004 - val_accuracy: 0.7930\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5252 - accuracy: 0.7764 - val_loss: 0.4989 - val_accuracy: 0.7930\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5288 - accuracy: 0.7764 - val_loss: 0.4994 - val_accuracy: 0.7930\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5298 - accuracy: 0.7764 - val_loss: 0.5014 - val_accuracy: 0.7930\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5251 - accuracy: 0.7764 - val_loss: 0.5003 - val_accuracy: 0.7930\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5196 - accuracy: 0.7764 - val_loss: 0.4947 - val_accuracy: 0.7930\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5211 - accuracy: 0.7764 - val_loss: 0.4991 - val_accuracy: 0.7930\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.5270 - accuracy: 0.7764 - val_loss: 0.4900 - val_accuracy: 0.7930\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5152 - accuracy: 0.7764 - val_loss: 0.4934 - val_accuracy: 0.7930\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5184 - accuracy: 0.7764 - val_loss: 0.4933 - val_accuracy: 0.7930\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5250 - accuracy: 0.7764 - val_loss: 0.4981 - val_accuracy: 0.7930\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5257 - accuracy: 0.7764 - val_loss: 0.4981 - val_accuracy: 0.7930\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5203 - accuracy: 0.7764 - val_loss: 0.4913 - val_accuracy: 0.7930\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5218 - accuracy: 0.7764 - val_loss: 0.5012 - val_accuracy: 0.7930\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5221 - accuracy: 0.7764 - val_loss: 0.4994 - val_accuracy: 0.7930\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5248 - accuracy: 0.7764 - val_loss: 0.4981 - val_accuracy: 0.7930\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5235 - accuracy: 0.7764 - val_loss: 0.4991 - val_accuracy: 0.7930\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5258 - accuracy: 0.7764 - val_loss: 0.4970 - val_accuracy: 0.7930\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5237 - accuracy: 0.7764 - val_loss: 0.4976 - val_accuracy: 0.7930\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5179 - accuracy: 0.7764 - val_loss: 0.4949 - val_accuracy: 0.7930\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5236 - accuracy: 0.7764 - val_loss: 0.4975 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4975 - accuracy: 0.7930\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 3s 24ms/step - loss: 0.6401 - accuracy: 0.6680 - val_loss: 0.5140 - val_accuracy: 0.7930\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5599 - accuracy: 0.7695 - val_loss: 0.5096 - val_accuracy: 0.7930\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5754 - accuracy: 0.7705 - val_loss: 0.5179 - val_accuracy: 0.7930\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5591 - accuracy: 0.7734 - val_loss: 0.5148 - val_accuracy: 0.7930\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5536 - accuracy: 0.7725 - val_loss: 0.5155 - val_accuracy: 0.7930\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5491 - accuracy: 0.7744 - val_loss: 0.5093 - val_accuracy: 0.7930\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5463 - accuracy: 0.7764 - val_loss: 0.5144 - val_accuracy: 0.7930\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5435 - accuracy: 0.7764 - val_loss: 0.5120 - val_accuracy: 0.7930\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5432 - accuracy: 0.7764 - val_loss: 0.5134 - val_accuracy: 0.7930\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5426 - accuracy: 0.7764 - val_loss: 0.5131 - val_accuracy: 0.7930\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5418 - accuracy: 0.7764 - val_loss: 0.5155 - val_accuracy: 0.7930\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5439 - accuracy: 0.7764 - val_loss: 0.5168 - val_accuracy: 0.7930\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5371 - accuracy: 0.7773 - val_loss: 0.5175 - val_accuracy: 0.7930\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5386 - accuracy: 0.7764 - val_loss: 0.5172 - val_accuracy: 0.7930\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5284 - accuracy: 0.7764 - val_loss: 0.5133 - val_accuracy: 0.7930\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5275 - accuracy: 0.7764 - val_loss: 0.5141 - val_accuracy: 0.7930\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5478 - accuracy: 0.7764 - val_loss: 0.5156 - val_accuracy: 0.7930\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5373 - accuracy: 0.7764 - val_loss: 0.5186 - val_accuracy: 0.7930\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5328 - accuracy: 0.7764 - val_loss: 0.5121 - val_accuracy: 0.7930\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5337 - accuracy: 0.7764 - val_loss: 0.5141 - val_accuracy: 0.7930\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5381 - accuracy: 0.7764 - val_loss: 0.5160 - val_accuracy: 0.7930\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5355 - accuracy: 0.7764 - val_loss: 0.5154 - val_accuracy: 0.7930\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5361 - accuracy: 0.7764 - val_loss: 0.5202 - val_accuracy: 0.7930\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5322 - accuracy: 0.7764 - val_loss: 0.5168 - val_accuracy: 0.7930\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5312 - accuracy: 0.7764 - val_loss: 0.5171 - val_accuracy: 0.7930\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5338 - accuracy: 0.7764 - val_loss: 0.5151 - val_accuracy: 0.7930\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5243 - accuracy: 0.7764 - val_loss: 0.5140 - val_accuracy: 0.7930\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5330 - accuracy: 0.7764 - val_loss: 0.5125 - val_accuracy: 0.7930\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5298 - accuracy: 0.7764 - val_loss: 0.5142 - val_accuracy: 0.7930\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5293 - accuracy: 0.7764 - val_loss: 0.5135 - val_accuracy: 0.7930\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5322 - accuracy: 0.7764 - val_loss: 0.5169 - val_accuracy: 0.7930\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5204 - accuracy: 0.7764 - val_loss: 0.5123 - val_accuracy: 0.7930\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5366 - accuracy: 0.7764 - val_loss: 0.5170 - val_accuracy: 0.7930\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5284 - accuracy: 0.7764 - val_loss: 0.5148 - val_accuracy: 0.7930\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5319 - accuracy: 0.7764 - val_loss: 0.5163 - val_accuracy: 0.7930\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5318 - accuracy: 0.7764 - val_loss: 0.5163 - val_accuracy: 0.7930\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5295 - accuracy: 0.7764 - val_loss: 0.5165 - val_accuracy: 0.7930\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.5309 - accuracy: 0.7764 - val_loss: 0.5139 - val_accuracy: 0.7930\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.5255 - accuracy: 0.7764 - val_loss: 0.5135 - val_accuracy: 0.7930\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5292 - accuracy: 0.7764 - val_loss: 0.5123 - val_accuracy: 0.7930\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5331 - accuracy: 0.7764 - val_loss: 0.5145 - val_accuracy: 0.7930\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5318 - accuracy: 0.7764 - val_loss: 0.5122 - val_accuracy: 0.7930\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.5261 - accuracy: 0.7764 - val_loss: 0.5117 - val_accuracy: 0.7930\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5243 - accuracy: 0.7764 - val_loss: 0.5114 - val_accuracy: 0.7930\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5269 - accuracy: 0.7764 - val_loss: 0.5105 - val_accuracy: 0.7930\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5246 - accuracy: 0.7764 - val_loss: 0.5122 - val_accuracy: 0.7930\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5254 - accuracy: 0.7764 - val_loss: 0.5102 - val_accuracy: 0.7930\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5260 - accuracy: 0.7764 - val_loss: 0.5114 - val_accuracy: 0.7930\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5295 - accuracy: 0.7764 - val_loss: 0.5096 - val_accuracy: 0.7930\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5239 - accuracy: 0.7764 - val_loss: 0.5107 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5107 - accuracy: 0.7930\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 4s 36ms/step - loss: 0.6111 - accuracy: 0.6895 - val_loss: 0.5180 - val_accuracy: 0.7930\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5595 - accuracy: 0.7725 - val_loss: 0.5142 - val_accuracy: 0.7930\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.5474 - accuracy: 0.7715 - val_loss: 0.5175 - val_accuracy: 0.7930\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5634 - accuracy: 0.7666 - val_loss: 0.5186 - val_accuracy: 0.7930\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5581 - accuracy: 0.7734 - val_loss: 0.5149 - val_accuracy: 0.7930\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5504 - accuracy: 0.7754 - val_loss: 0.5163 - val_accuracy: 0.7930\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5530 - accuracy: 0.7764 - val_loss: 0.5140 - val_accuracy: 0.7930\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5487 - accuracy: 0.7764 - val_loss: 0.5162 - val_accuracy: 0.7930\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5468 - accuracy: 0.7764 - val_loss: 0.5235 - val_accuracy: 0.7930\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5446 - accuracy: 0.7764 - val_loss: 0.5153 - val_accuracy: 0.7930\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5576 - accuracy: 0.7764 - val_loss: 0.5235 - val_accuracy: 0.7930\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5457 - accuracy: 0.7764 - val_loss: 0.5165 - val_accuracy: 0.7930\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5426 - accuracy: 0.7764 - val_loss: 0.5128 - val_accuracy: 0.7930\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5403 - accuracy: 0.7764 - val_loss: 0.5178 - val_accuracy: 0.7930\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5430 - accuracy: 0.7764 - val_loss: 0.5154 - val_accuracy: 0.7930\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5468 - accuracy: 0.7764 - val_loss: 0.5215 - val_accuracy: 0.7930\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5403 - accuracy: 0.7764 - val_loss: 0.5221 - val_accuracy: 0.7930\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5412 - accuracy: 0.7764 - val_loss: 0.5167 - val_accuracy: 0.7930\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5320 - accuracy: 0.7764 - val_loss: 0.5139 - val_accuracy: 0.7930\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5340 - accuracy: 0.7764 - val_loss: 0.5164 - val_accuracy: 0.7930\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5325 - accuracy: 0.7764 - val_loss: 0.5150 - val_accuracy: 0.7930\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5287 - accuracy: 0.7764 - val_loss: 0.5146 - val_accuracy: 0.7930\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5372 - accuracy: 0.7764 - val_loss: 0.5149 - val_accuracy: 0.7930\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5301 - accuracy: 0.7764 - val_loss: 0.5132 - val_accuracy: 0.7930\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5364 - accuracy: 0.7764 - val_loss: 0.5137 - val_accuracy: 0.7930\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5226 - accuracy: 0.7764 - val_loss: 0.5128 - val_accuracy: 0.7930\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5329 - accuracy: 0.7764 - val_loss: 0.5175 - val_accuracy: 0.7930\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5274 - accuracy: 0.7764 - val_loss: 0.5129 - val_accuracy: 0.7930\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5310 - accuracy: 0.7764 - val_loss: 0.5165 - val_accuracy: 0.7930\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5279 - accuracy: 0.7764 - val_loss: 0.5129 - val_accuracy: 0.7930\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5296 - accuracy: 0.7764 - val_loss: 0.5140 - val_accuracy: 0.7930\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5341 - accuracy: 0.7764 - val_loss: 0.5133 - val_accuracy: 0.7930\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5233 - accuracy: 0.7764 - val_loss: 0.5132 - val_accuracy: 0.7930\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5326 - accuracy: 0.7764 - val_loss: 0.5164 - val_accuracy: 0.7930\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5313 - accuracy: 0.7764 - val_loss: 0.5143 - val_accuracy: 0.7930\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5303 - accuracy: 0.7764 - val_loss: 0.5138 - val_accuracy: 0.7930\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5288 - accuracy: 0.7764 - val_loss: 0.5151 - val_accuracy: 0.7930\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5374 - accuracy: 0.7764 - val_loss: 0.5164 - val_accuracy: 0.7930\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5284 - accuracy: 0.7764 - val_loss: 0.5143 - val_accuracy: 0.7930\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5289 - accuracy: 0.7764 - val_loss: 0.5124 - val_accuracy: 0.7930\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5246 - accuracy: 0.7764 - val_loss: 0.5102 - val_accuracy: 0.7930\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5305 - accuracy: 0.7764 - val_loss: 0.5112 - val_accuracy: 0.7930\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5286 - accuracy: 0.7764 - val_loss: 0.5113 - val_accuracy: 0.7930\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5258 - accuracy: 0.7764 - val_loss: 0.5105 - val_accuracy: 0.7930\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5260 - accuracy: 0.7764 - val_loss: 0.5123 - val_accuracy: 0.7930\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5340 - accuracy: 0.7764 - val_loss: 0.5136 - val_accuracy: 0.7930\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5284 - accuracy: 0.7764 - val_loss: 0.5119 - val_accuracy: 0.7930\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5262 - accuracy: 0.7764 - val_loss: 0.5102 - val_accuracy: 0.7930\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5249 - accuracy: 0.7764 - val_loss: 0.5129 - val_accuracy: 0.7930\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5289 - accuracy: 0.7764 - val_loss: 0.5084 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7930\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 3s 21ms/step - loss: 0.5928 - accuracy: 0.7236 - val_loss: 0.5265 - val_accuracy: 0.7930\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5302 - accuracy: 0.7734 - val_loss: 0.5136 - val_accuracy: 0.7930\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5670 - accuracy: 0.7773 - val_loss: 0.5183 - val_accuracy: 0.7930\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5550 - accuracy: 0.7734 - val_loss: 0.5230 - val_accuracy: 0.7930\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5487 - accuracy: 0.7764 - val_loss: 0.5248 - val_accuracy: 0.7930\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5516 - accuracy: 0.7764 - val_loss: 0.5263 - val_accuracy: 0.7930\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5466 - accuracy: 0.7754 - val_loss: 0.5335 - val_accuracy: 0.7930\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5513 - accuracy: 0.7754 - val_loss: 0.5316 - val_accuracy: 0.7930\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5397 - accuracy: 0.7764 - val_loss: 0.5276 - val_accuracy: 0.7930\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5406 - accuracy: 0.7764 - val_loss: 0.5286 - val_accuracy: 0.7930\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5481 - accuracy: 0.7764 - val_loss: 0.5299 - val_accuracy: 0.7930\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5389 - accuracy: 0.7764 - val_loss: 0.5321 - val_accuracy: 0.7930\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5414 - accuracy: 0.7764 - val_loss: 0.5296 - val_accuracy: 0.7930\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5367 - accuracy: 0.7764 - val_loss: 0.5330 - val_accuracy: 0.7930\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5405 - accuracy: 0.7764 - val_loss: 0.5324 - val_accuracy: 0.7930\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5407 - accuracy: 0.7764 - val_loss: 0.5273 - val_accuracy: 0.7930\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5422 - accuracy: 0.7764 - val_loss: 0.5300 - val_accuracy: 0.7930\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5344 - accuracy: 0.7764 - val_loss: 0.5253 - val_accuracy: 0.7930\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5340 - accuracy: 0.7764 - val_loss: 0.5232 - val_accuracy: 0.7930\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5347 - accuracy: 0.7764 - val_loss: 0.5223 - val_accuracy: 0.7930\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5394 - accuracy: 0.7764 - val_loss: 0.5243 - val_accuracy: 0.7930\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5385 - accuracy: 0.7764 - val_loss: 0.5233 - val_accuracy: 0.7930\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5399 - accuracy: 0.7764 - val_loss: 0.5284 - val_accuracy: 0.7930\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5330 - accuracy: 0.7764 - val_loss: 0.5250 - val_accuracy: 0.7930\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5355 - accuracy: 0.7764 - val_loss: 0.5225 - val_accuracy: 0.7930\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5371 - accuracy: 0.7764 - val_loss: 0.5263 - val_accuracy: 0.7930\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5346 - accuracy: 0.7764 - val_loss: 0.5248 - val_accuracy: 0.7930\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5346 - accuracy: 0.7764 - val_loss: 0.5255 - val_accuracy: 0.7930\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5335 - accuracy: 0.7764 - val_loss: 0.5242 - val_accuracy: 0.7930\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5274 - accuracy: 0.7764 - val_loss: 0.5191 - val_accuracy: 0.7930\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5267 - accuracy: 0.7764 - val_loss: 0.5211 - val_accuracy: 0.7930\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5355 - accuracy: 0.7764 - val_loss: 0.5225 - val_accuracy: 0.7930\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5325 - accuracy: 0.7764 - val_loss: 0.5186 - val_accuracy: 0.7930\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5335 - accuracy: 0.7764 - val_loss: 0.5239 - val_accuracy: 0.7930\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5263 - accuracy: 0.7764 - val_loss: 0.5194 - val_accuracy: 0.7930\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5342 - accuracy: 0.7764 - val_loss: 0.5160 - val_accuracy: 0.7930\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5393 - accuracy: 0.7764 - val_loss: 0.5255 - val_accuracy: 0.7930\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5319 - accuracy: 0.7764 - val_loss: 0.5212 - val_accuracy: 0.7930\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5291 - accuracy: 0.7764 - val_loss: 0.5219 - val_accuracy: 0.7930\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5337 - accuracy: 0.7764 - val_loss: 0.5240 - val_accuracy: 0.7930\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5309 - accuracy: 0.7764 - val_loss: 0.5227 - val_accuracy: 0.7930\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5276 - accuracy: 0.7764 - val_loss: 0.5178 - val_accuracy: 0.7930\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5338 - accuracy: 0.7764 - val_loss: 0.5230 - val_accuracy: 0.7930\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5323 - accuracy: 0.7764 - val_loss: 0.5193 - val_accuracy: 0.7930\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5318 - accuracy: 0.7764 - val_loss: 0.5206 - val_accuracy: 0.7930\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5381 - accuracy: 0.7764 - val_loss: 0.5202 - val_accuracy: 0.7930\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5342 - accuracy: 0.7764 - val_loss: 0.5208 - val_accuracy: 0.7930\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5242 - accuracy: 0.7764 - val_loss: 0.5198 - val_accuracy: 0.7930\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5266 - accuracy: 0.7764 - val_loss: 0.5213 - val_accuracy: 0.7930\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5305 - accuracy: 0.7764 - val_loss: 0.5193 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5193 - accuracy: 0.7930\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 3s 22ms/step - loss: 0.5889 - accuracy: 0.7490 - val_loss: 0.5249 - val_accuracy: 0.7930\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5908 - accuracy: 0.7676 - val_loss: 0.5250 - val_accuracy: 0.7930\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5629 - accuracy: 0.7676 - val_loss: 0.5224 - val_accuracy: 0.7930\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5504 - accuracy: 0.7725 - val_loss: 0.5197 - val_accuracy: 0.7930\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5428 - accuracy: 0.7783 - val_loss: 0.5197 - val_accuracy: 0.7930\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5514 - accuracy: 0.7744 - val_loss: 0.5223 - val_accuracy: 0.7930\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5377 - accuracy: 0.7754 - val_loss: 0.5193 - val_accuracy: 0.7930\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5405 - accuracy: 0.7734 - val_loss: 0.5164 - val_accuracy: 0.7930\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5538 - accuracy: 0.7764 - val_loss: 0.5284 - val_accuracy: 0.7930\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5357 - accuracy: 0.7773 - val_loss: 0.5208 - val_accuracy: 0.7930\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5329 - accuracy: 0.7764 - val_loss: 0.5198 - val_accuracy: 0.7930\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5426 - accuracy: 0.7773 - val_loss: 0.5219 - val_accuracy: 0.7930\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5420 - accuracy: 0.7764 - val_loss: 0.5243 - val_accuracy: 0.7930\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5272 - accuracy: 0.7764 - val_loss: 0.5160 - val_accuracy: 0.7930\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5434 - accuracy: 0.7754 - val_loss: 0.5164 - val_accuracy: 0.7930\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5347 - accuracy: 0.7764 - val_loss: 0.5109 - val_accuracy: 0.7930\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5365 - accuracy: 0.7764 - val_loss: 0.5132 - val_accuracy: 0.7930\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5314 - accuracy: 0.7764 - val_loss: 0.5141 - val_accuracy: 0.7930\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5329 - accuracy: 0.7764 - val_loss: 0.5071 - val_accuracy: 0.7930\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5315 - accuracy: 0.7764 - val_loss: 0.5135 - val_accuracy: 0.7930\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5324 - accuracy: 0.7764 - val_loss: 0.5118 - val_accuracy: 0.7930\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5301 - accuracy: 0.7764 - val_loss: 0.5070 - val_accuracy: 0.7930\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5339 - accuracy: 0.7764 - val_loss: 0.5101 - val_accuracy: 0.7930\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5238 - accuracy: 0.7764 - val_loss: 0.5057 - val_accuracy: 0.7930\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5266 - accuracy: 0.7764 - val_loss: 0.5063 - val_accuracy: 0.7930\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5298 - accuracy: 0.7764 - val_loss: 0.5024 - val_accuracy: 0.7930\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5290 - accuracy: 0.7764 - val_loss: 0.5071 - val_accuracy: 0.7930\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5219 - accuracy: 0.7764 - val_loss: 0.5017 - val_accuracy: 0.7930\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5231 - accuracy: 0.7764 - val_loss: 0.5003 - val_accuracy: 0.7930\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5331 - accuracy: 0.7764 - val_loss: 0.5012 - val_accuracy: 0.7930\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5289 - accuracy: 0.7764 - val_loss: 0.5012 - val_accuracy: 0.7930\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5298 - accuracy: 0.7764 - val_loss: 0.5044 - val_accuracy: 0.7930\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5262 - accuracy: 0.7764 - val_loss: 0.5032 - val_accuracy: 0.7930\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5186 - accuracy: 0.7764 - val_loss: 0.5021 - val_accuracy: 0.7930\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5309 - accuracy: 0.7764 - val_loss: 0.5044 - val_accuracy: 0.7930\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5258 - accuracy: 0.7764 - val_loss: 0.5030 - val_accuracy: 0.7930\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5222 - accuracy: 0.7764 - val_loss: 0.5043 - val_accuracy: 0.7930\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5272 - accuracy: 0.7764 - val_loss: 0.5046 - val_accuracy: 0.7930\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5192 - accuracy: 0.7764 - val_loss: 0.4973 - val_accuracy: 0.7930\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5205 - accuracy: 0.7764 - val_loss: 0.5001 - val_accuracy: 0.7930\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5166 - accuracy: 0.7764 - val_loss: 0.4949 - val_accuracy: 0.7930\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5118 - accuracy: 0.7764 - val_loss: 0.4922 - val_accuracy: 0.7930\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5255 - accuracy: 0.7764 - val_loss: 0.5013 - val_accuracy: 0.7930\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5190 - accuracy: 0.7764 - val_loss: 0.4968 - val_accuracy: 0.7930\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5184 - accuracy: 0.7764 - val_loss: 0.4996 - val_accuracy: 0.7930\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5183 - accuracy: 0.7764 - val_loss: 0.4951 - val_accuracy: 0.7930\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5229 - accuracy: 0.7764 - val_loss: 0.4970 - val_accuracy: 0.7930\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5173 - accuracy: 0.7764 - val_loss: 0.4943 - val_accuracy: 0.7930\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5089 - accuracy: 0.7754 - val_loss: 0.4916 - val_accuracy: 0.7930\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5227 - accuracy: 0.7764 - val_loss: 0.5000 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.7930\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 3s 21ms/step - loss: 0.6364 - accuracy: 0.6904 - val_loss: 0.5179 - val_accuracy: 0.7930\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5651 - accuracy: 0.7656 - val_loss: 0.5203 - val_accuracy: 0.7930\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5655 - accuracy: 0.7725 - val_loss: 0.5198 - val_accuracy: 0.7930\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5628 - accuracy: 0.7734 - val_loss: 0.5249 - val_accuracy: 0.7930\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5509 - accuracy: 0.7754 - val_loss: 0.5207 - val_accuracy: 0.7930\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5358 - accuracy: 0.7744 - val_loss: 0.5177 - val_accuracy: 0.7930\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5579 - accuracy: 0.7754 - val_loss: 0.5291 - val_accuracy: 0.7930\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5431 - accuracy: 0.7773 - val_loss: 0.5233 - val_accuracy: 0.7930\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5414 - accuracy: 0.7764 - val_loss: 0.5264 - val_accuracy: 0.7930\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5473 - accuracy: 0.7764 - val_loss: 0.5244 - val_accuracy: 0.7930\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5411 - accuracy: 0.7764 - val_loss: 0.5232 - val_accuracy: 0.7930\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5380 - accuracy: 0.7764 - val_loss: 0.5252 - val_accuracy: 0.7930\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5404 - accuracy: 0.7764 - val_loss: 0.5242 - val_accuracy: 0.7930\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5415 - accuracy: 0.7764 - val_loss: 0.5227 - val_accuracy: 0.7930\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5432 - accuracy: 0.7764 - val_loss: 0.5246 - val_accuracy: 0.7930\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5425 - accuracy: 0.7764 - val_loss: 0.5231 - val_accuracy: 0.7930\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5387 - accuracy: 0.7764 - val_loss: 0.5235 - val_accuracy: 0.7930\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5354 - accuracy: 0.7764 - val_loss: 0.5234 - val_accuracy: 0.7930\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5380 - accuracy: 0.7764 - val_loss: 0.5224 - val_accuracy: 0.7930\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5302 - accuracy: 0.7764 - val_loss: 0.5194 - val_accuracy: 0.7930\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5380 - accuracy: 0.7764 - val_loss: 0.5207 - val_accuracy: 0.7930\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5311 - accuracy: 0.7764 - val_loss: 0.5181 - val_accuracy: 0.7930\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5412 - accuracy: 0.7764 - val_loss: 0.5188 - val_accuracy: 0.7930\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5242 - accuracy: 0.7764 - val_loss: 0.5179 - val_accuracy: 0.7930\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5297 - accuracy: 0.7764 - val_loss: 0.5175 - val_accuracy: 0.7930\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5294 - accuracy: 0.7764 - val_loss: 0.5144 - val_accuracy: 0.7930\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5349 - accuracy: 0.7764 - val_loss: 0.5176 - val_accuracy: 0.7930\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5317 - accuracy: 0.7764 - val_loss: 0.5169 - val_accuracy: 0.7930\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5310 - accuracy: 0.7764 - val_loss: 0.5210 - val_accuracy: 0.7930\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5277 - accuracy: 0.7764 - val_loss: 0.5140 - val_accuracy: 0.7930\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5304 - accuracy: 0.7764 - val_loss: 0.5147 - val_accuracy: 0.7930\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5285 - accuracy: 0.7764 - val_loss: 0.5183 - val_accuracy: 0.7930\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5267 - accuracy: 0.7764 - val_loss: 0.5074 - val_accuracy: 0.7930\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5238 - accuracy: 0.7764 - val_loss: 0.5149 - val_accuracy: 0.7930\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5255 - accuracy: 0.7764 - val_loss: 0.5056 - val_accuracy: 0.7930\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5227 - accuracy: 0.7764 - val_loss: 0.5107 - val_accuracy: 0.7930\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5274 - accuracy: 0.7764 - val_loss: 0.5140 - val_accuracy: 0.7930\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5209 - accuracy: 0.7764 - val_loss: 0.5057 - val_accuracy: 0.7930\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5237 - accuracy: 0.7764 - val_loss: 0.5041 - val_accuracy: 0.7930\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5216 - accuracy: 0.7764 - val_loss: 0.5055 - val_accuracy: 0.7930\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5222 - accuracy: 0.7764 - val_loss: 0.5035 - val_accuracy: 0.7930\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5288 - accuracy: 0.7764 - val_loss: 0.5084 - val_accuracy: 0.7930\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5266 - accuracy: 0.7764 - val_loss: 0.5056 - val_accuracy: 0.7930\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5140 - accuracy: 0.7764 - val_loss: 0.5054 - val_accuracy: 0.7930\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5218 - accuracy: 0.7764 - val_loss: 0.5074 - val_accuracy: 0.7930\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5176 - accuracy: 0.7764 - val_loss: 0.5035 - val_accuracy: 0.7930\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5173 - accuracy: 0.7764 - val_loss: 0.5064 - val_accuracy: 0.7930\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5170 - accuracy: 0.7764 - val_loss: 0.5008 - val_accuracy: 0.7930\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5183 - accuracy: 0.7764 - val_loss: 0.5045 - val_accuracy: 0.7930\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5191 - accuracy: 0.7764 - val_loss: 0.5053 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7930\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 3s 20ms/step - loss: 0.6053 - accuracy: 0.6855 - val_loss: 0.5119 - val_accuracy: 0.7930\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5675 - accuracy: 0.7695 - val_loss: 0.5097 - val_accuracy: 0.7930\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5487 - accuracy: 0.7754 - val_loss: 0.5084 - val_accuracy: 0.7930\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5471 - accuracy: 0.7734 - val_loss: 0.5122 - val_accuracy: 0.7930\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5610 - accuracy: 0.7725 - val_loss: 0.5118 - val_accuracy: 0.7930\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5611 - accuracy: 0.7764 - val_loss: 0.5146 - val_accuracy: 0.7930\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5415 - accuracy: 0.7754 - val_loss: 0.5095 - val_accuracy: 0.7930\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5464 - accuracy: 0.7764 - val_loss: 0.5116 - val_accuracy: 0.7930\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5507 - accuracy: 0.7744 - val_loss: 0.5165 - val_accuracy: 0.7930\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5414 - accuracy: 0.7764 - val_loss: 0.5137 - val_accuracy: 0.7930\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5406 - accuracy: 0.7764 - val_loss: 0.5163 - val_accuracy: 0.7930\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5387 - accuracy: 0.7764 - val_loss: 0.5123 - val_accuracy: 0.7930\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5314 - accuracy: 0.7764 - val_loss: 0.5101 - val_accuracy: 0.7930\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5357 - accuracy: 0.7764 - val_loss: 0.5117 - val_accuracy: 0.7930\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5442 - accuracy: 0.7764 - val_loss: 0.5106 - val_accuracy: 0.7930\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5318 - accuracy: 0.7764 - val_loss: 0.5126 - val_accuracy: 0.7930\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5341 - accuracy: 0.7764 - val_loss: 0.5094 - val_accuracy: 0.7930\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5400 - accuracy: 0.7764 - val_loss: 0.5134 - val_accuracy: 0.7930\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5282 - accuracy: 0.7764 - val_loss: 0.5111 - val_accuracy: 0.7930\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5375 - accuracy: 0.7764 - val_loss: 0.5106 - val_accuracy: 0.7930\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5401 - accuracy: 0.7764 - val_loss: 0.5113 - val_accuracy: 0.7930\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5352 - accuracy: 0.7764 - val_loss: 0.5131 - val_accuracy: 0.7930\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5278 - accuracy: 0.7764 - val_loss: 0.5114 - val_accuracy: 0.7930\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5300 - accuracy: 0.7764 - val_loss: 0.5115 - val_accuracy: 0.7930\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5301 - accuracy: 0.7764 - val_loss: 0.5107 - val_accuracy: 0.7930\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5306 - accuracy: 0.7764 - val_loss: 0.5110 - val_accuracy: 0.7930\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5304 - accuracy: 0.7764 - val_loss: 0.5099 - val_accuracy: 0.7930\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5331 - accuracy: 0.7764 - val_loss: 0.5111 - val_accuracy: 0.7930\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5243 - accuracy: 0.7764 - val_loss: 0.5102 - val_accuracy: 0.7930\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5303 - accuracy: 0.7764 - val_loss: 0.5123 - val_accuracy: 0.7930\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5293 - accuracy: 0.7764 - val_loss: 0.5142 - val_accuracy: 0.7930\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5321 - accuracy: 0.7764 - val_loss: 0.5108 - val_accuracy: 0.7930\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5286 - accuracy: 0.7764 - val_loss: 0.5132 - val_accuracy: 0.7930\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5340 - accuracy: 0.7764 - val_loss: 0.5117 - val_accuracy: 0.7930\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5285 - accuracy: 0.7764 - val_loss: 0.5119 - val_accuracy: 0.7930\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5295 - accuracy: 0.7764 - val_loss: 0.5120 - val_accuracy: 0.7930\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5322 - accuracy: 0.7764 - val_loss: 0.5109 - val_accuracy: 0.7930\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5305 - accuracy: 0.7764 - val_loss: 0.5144 - val_accuracy: 0.7930\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5324 - accuracy: 0.7764 - val_loss: 0.5115 - val_accuracy: 0.7930\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5265 - accuracy: 0.7764 - val_loss: 0.5104 - val_accuracy: 0.7930\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5286 - accuracy: 0.7764 - val_loss: 0.5126 - val_accuracy: 0.7930\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5353 - accuracy: 0.7764 - val_loss: 0.5110 - val_accuracy: 0.7930\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5326 - accuracy: 0.7764 - val_loss: 0.5115 - val_accuracy: 0.7930\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5249 - accuracy: 0.7764 - val_loss: 0.5115 - val_accuracy: 0.7930\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5256 - accuracy: 0.7764 - val_loss: 0.5086 - val_accuracy: 0.7930\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5314 - accuracy: 0.7764 - val_loss: 0.5107 - val_accuracy: 0.7930\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5325 - accuracy: 0.7764 - val_loss: 0.5112 - val_accuracy: 0.7930\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5247 - accuracy: 0.7764 - val_loss: 0.5091 - val_accuracy: 0.7930\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5302 - accuracy: 0.7764 - val_loss: 0.5128 - val_accuracy: 0.7930\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5262 - accuracy: 0.7764 - val_loss: 0.5117 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5117 - accuracy: 0.7930\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 4s 32ms/step - loss: 0.5941 - accuracy: 0.7383 - val_loss: 0.5250 - val_accuracy: 0.7930\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5677 - accuracy: 0.7744 - val_loss: 0.5212 - val_accuracy: 0.7930\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5644 - accuracy: 0.7764 - val_loss: 0.5250 - val_accuracy: 0.7930\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5504 - accuracy: 0.7725 - val_loss: 0.5268 - val_accuracy: 0.7930\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5445 - accuracy: 0.7764 - val_loss: 0.5256 - val_accuracy: 0.7930\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5402 - accuracy: 0.7773 - val_loss: 0.5213 - val_accuracy: 0.7930\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5527 - accuracy: 0.7744 - val_loss: 0.5262 - val_accuracy: 0.7930\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5517 - accuracy: 0.7773 - val_loss: 0.5273 - val_accuracy: 0.7930\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5440 - accuracy: 0.7764 - val_loss: 0.5231 - val_accuracy: 0.7930\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5361 - accuracy: 0.7783 - val_loss: 0.5237 - val_accuracy: 0.7930\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5451 - accuracy: 0.7764 - val_loss: 0.5274 - val_accuracy: 0.7930\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5417 - accuracy: 0.7764 - val_loss: 0.5291 - val_accuracy: 0.7930\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5375 - accuracy: 0.7764 - val_loss: 0.5265 - val_accuracy: 0.7930\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5304 - accuracy: 0.7764 - val_loss: 0.5273 - val_accuracy: 0.7930\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5310 - accuracy: 0.7764 - val_loss: 0.5239 - val_accuracy: 0.7930\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5415 - accuracy: 0.7764 - val_loss: 0.5271 - val_accuracy: 0.7930\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5399 - accuracy: 0.7764 - val_loss: 0.5256 - val_accuracy: 0.7930\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5377 - accuracy: 0.7764 - val_loss: 0.5280 - val_accuracy: 0.7930\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5338 - accuracy: 0.7764 - val_loss: 0.5257 - val_accuracy: 0.7930\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5414 - accuracy: 0.7764 - val_loss: 0.5260 - val_accuracy: 0.7930\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5385 - accuracy: 0.7764 - val_loss: 0.5226 - val_accuracy: 0.7930\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5447 - accuracy: 0.7764 - val_loss: 0.5247 - val_accuracy: 0.7930\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5400 - accuracy: 0.7764 - val_loss: 0.5270 - val_accuracy: 0.7930\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5349 - accuracy: 0.7764 - val_loss: 0.5281 - val_accuracy: 0.7930\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5269 - accuracy: 0.7764 - val_loss: 0.5242 - val_accuracy: 0.7930\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5299 - accuracy: 0.7764 - val_loss: 0.5280 - val_accuracy: 0.7930\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5296 - accuracy: 0.7764 - val_loss: 0.5239 - val_accuracy: 0.7930\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5271 - accuracy: 0.7764 - val_loss: 0.5236 - val_accuracy: 0.7930\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5357 - accuracy: 0.7764 - val_loss: 0.5221 - val_accuracy: 0.7930\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5339 - accuracy: 0.7764 - val_loss: 0.5249 - val_accuracy: 0.7930\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5319 - accuracy: 0.7764 - val_loss: 0.5280 - val_accuracy: 0.7930\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5331 - accuracy: 0.7764 - val_loss: 0.5246 - val_accuracy: 0.7930\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5303 - accuracy: 0.7764 - val_loss: 0.5230 - val_accuracy: 0.7930\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5350 - accuracy: 0.7764 - val_loss: 0.5251 - val_accuracy: 0.7930\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5363 - accuracy: 0.7764 - val_loss: 0.5238 - val_accuracy: 0.7930\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5328 - accuracy: 0.7764 - val_loss: 0.5238 - val_accuracy: 0.7930\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5333 - accuracy: 0.7764 - val_loss: 0.5219 - val_accuracy: 0.7930\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5245 - accuracy: 0.7764 - val_loss: 0.5216 - val_accuracy: 0.7930\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5352 - accuracy: 0.7764 - val_loss: 0.5232 - val_accuracy: 0.7930\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5337 - accuracy: 0.7764 - val_loss: 0.5249 - val_accuracy: 0.7930\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5351 - accuracy: 0.7764 - val_loss: 0.5228 - val_accuracy: 0.7930\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5323 - accuracy: 0.7764 - val_loss: 0.5225 - val_accuracy: 0.7930\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5315 - accuracy: 0.7764 - val_loss: 0.5243 - val_accuracy: 0.7930\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5321 - accuracy: 0.7764 - val_loss: 0.5241 - val_accuracy: 0.7930\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5363 - accuracy: 0.7764 - val_loss: 0.5212 - val_accuracy: 0.7930\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5345 - accuracy: 0.7764 - val_loss: 0.5230 - val_accuracy: 0.7930\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5301 - accuracy: 0.7764 - val_loss: 0.5198 - val_accuracy: 0.7930\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5289 - accuracy: 0.7764 - val_loss: 0.5203 - val_accuracy: 0.7930\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5309 - accuracy: 0.7764 - val_loss: 0.5203 - val_accuracy: 0.7930\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5361 - accuracy: 0.7764 - val_loss: 0.5199 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5199 - accuracy: 0.7930\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 3s 30ms/step - loss: 0.5939 - accuracy: 0.7197 - val_loss: 0.5182 - val_accuracy: 0.7930\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5697 - accuracy: 0.7744 - val_loss: 0.5178 - val_accuracy: 0.7930\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5613 - accuracy: 0.7705 - val_loss: 0.5172 - val_accuracy: 0.7930\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5434 - accuracy: 0.7695 - val_loss: 0.5190 - val_accuracy: 0.7930\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5595 - accuracy: 0.7754 - val_loss: 0.5181 - val_accuracy: 0.7930\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5490 - accuracy: 0.7725 - val_loss: 0.5236 - val_accuracy: 0.7930\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5412 - accuracy: 0.7754 - val_loss: 0.5155 - val_accuracy: 0.7930\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5339 - accuracy: 0.7764 - val_loss: 0.5152 - val_accuracy: 0.7930\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5338 - accuracy: 0.7754 - val_loss: 0.5149 - val_accuracy: 0.7930\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5367 - accuracy: 0.7764 - val_loss: 0.5114 - val_accuracy: 0.7930\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5420 - accuracy: 0.7764 - val_loss: 0.5130 - val_accuracy: 0.7930\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5353 - accuracy: 0.7764 - val_loss: 0.5123 - val_accuracy: 0.7930\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5292 - accuracy: 0.7754 - val_loss: 0.5109 - val_accuracy: 0.7930\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5285 - accuracy: 0.7764 - val_loss: 0.5119 - val_accuracy: 0.7930\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5319 - accuracy: 0.7764 - val_loss: 0.5098 - val_accuracy: 0.7930\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5351 - accuracy: 0.7764 - val_loss: 0.5130 - val_accuracy: 0.7930\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5318 - accuracy: 0.7764 - val_loss: 0.5101 - val_accuracy: 0.7930\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5233 - accuracy: 0.7764 - val_loss: 0.5071 - val_accuracy: 0.7930\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5218 - accuracy: 0.7764 - val_loss: 0.5061 - val_accuracy: 0.7930\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5232 - accuracy: 0.7764 - val_loss: 0.5079 - val_accuracy: 0.7930\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5313 - accuracy: 0.7764 - val_loss: 0.5098 - val_accuracy: 0.7930\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5202 - accuracy: 0.7764 - val_loss: 0.5059 - val_accuracy: 0.7930\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5243 - accuracy: 0.7764 - val_loss: 0.5056 - val_accuracy: 0.7930\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5296 - accuracy: 0.7764 - val_loss: 0.5063 - val_accuracy: 0.7930\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5272 - accuracy: 0.7764 - val_loss: 0.5084 - val_accuracy: 0.7930\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5187 - accuracy: 0.7764 - val_loss: 0.5087 - val_accuracy: 0.7930\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5151 - accuracy: 0.7764 - val_loss: 0.5090 - val_accuracy: 0.7930\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5245 - accuracy: 0.7754 - val_loss: 0.5111 - val_accuracy: 0.7930\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5252 - accuracy: 0.7764 - val_loss: 0.5102 - val_accuracy: 0.7930\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5240 - accuracy: 0.7764 - val_loss: 0.5088 - val_accuracy: 0.7930\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5229 - accuracy: 0.7764 - val_loss: 0.5076 - val_accuracy: 0.7930\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5163 - accuracy: 0.7764 - val_loss: 0.5069 - val_accuracy: 0.7930\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5120 - accuracy: 0.7764 - val_loss: 0.5082 - val_accuracy: 0.7930\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5223 - accuracy: 0.7764 - val_loss: 0.5081 - val_accuracy: 0.7930\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5176 - accuracy: 0.7764 - val_loss: 0.5084 - val_accuracy: 0.7930\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5190 - accuracy: 0.7764 - val_loss: 0.5109 - val_accuracy: 0.7930\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5142 - accuracy: 0.7764 - val_loss: 0.5060 - val_accuracy: 0.7930\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5143 - accuracy: 0.7764 - val_loss: 0.5085 - val_accuracy: 0.7930\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5167 - accuracy: 0.7764 - val_loss: 0.5070 - val_accuracy: 0.7930\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5141 - accuracy: 0.7764 - val_loss: 0.5075 - val_accuracy: 0.7930\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5140 - accuracy: 0.7764 - val_loss: 0.5097 - val_accuracy: 0.7930\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5132 - accuracy: 0.7764 - val_loss: 0.5102 - val_accuracy: 0.7930\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5104 - accuracy: 0.7764 - val_loss: 0.5077 - val_accuracy: 0.7930\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5099 - accuracy: 0.7764 - val_loss: 0.5094 - val_accuracy: 0.7930\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5066 - accuracy: 0.7764 - val_loss: 0.5096 - val_accuracy: 0.7930\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5108 - accuracy: 0.7764 - val_loss: 0.5087 - val_accuracy: 0.7930\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5116 - accuracy: 0.7764 - val_loss: 0.5107 - val_accuracy: 0.7930\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5136 - accuracy: 0.7764 - val_loss: 0.5101 - val_accuracy: 0.7930\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5050 - accuracy: 0.7764 - val_loss: 0.5092 - val_accuracy: 0.7930\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5116 - accuracy: 0.7764 - val_loss: 0.5107 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5107 - accuracy: 0.7930\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 3s 21ms/step - loss: 0.6036 - accuracy: 0.7119 - val_loss: 0.5202 - val_accuracy: 0.7930\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5671 - accuracy: 0.7754 - val_loss: 0.5202 - val_accuracy: 0.7930\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5536 - accuracy: 0.7744 - val_loss: 0.5229 - val_accuracy: 0.7930\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5580 - accuracy: 0.7715 - val_loss: 0.5243 - val_accuracy: 0.7930\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5544 - accuracy: 0.7744 - val_loss: 0.5230 - val_accuracy: 0.7930\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5541 - accuracy: 0.7764 - val_loss: 0.5296 - val_accuracy: 0.7930\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5460 - accuracy: 0.7764 - val_loss: 0.5243 - val_accuracy: 0.7930\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5449 - accuracy: 0.7754 - val_loss: 0.5231 - val_accuracy: 0.7930\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5427 - accuracy: 0.7764 - val_loss: 0.5224 - val_accuracy: 0.7930\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5366 - accuracy: 0.7764 - val_loss: 0.5223 - val_accuracy: 0.7930\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5464 - accuracy: 0.7764 - val_loss: 0.5244 - val_accuracy: 0.7930\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.5301 - accuracy: 0.7764 - val_loss: 0.5269 - val_accuracy: 0.7930\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.5350 - accuracy: 0.7764 - val_loss: 0.5227 - val_accuracy: 0.7930\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5370 - accuracy: 0.7764 - val_loss: 0.5209 - val_accuracy: 0.7930\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5432 - accuracy: 0.7764 - val_loss: 0.5249 - val_accuracy: 0.7930\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.5294 - accuracy: 0.7764 - val_loss: 0.5232 - val_accuracy: 0.7930\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.5347 - accuracy: 0.7764 - val_loss: 0.5269 - val_accuracy: 0.7930\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.5272 - accuracy: 0.7764 - val_loss: 0.5207 - val_accuracy: 0.7930\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5289 - accuracy: 0.7764 - val_loss: 0.5180 - val_accuracy: 0.7930\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5249 - accuracy: 0.7764 - val_loss: 0.5207 - val_accuracy: 0.7930\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5285 - accuracy: 0.7764 - val_loss: 0.5201 - val_accuracy: 0.7930\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5274 - accuracy: 0.7764 - val_loss: 0.5222 - val_accuracy: 0.7930\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5241 - accuracy: 0.7764 - val_loss: 0.5186 - val_accuracy: 0.7930\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5268 - accuracy: 0.7764 - val_loss: 0.5186 - val_accuracy: 0.7930\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5235 - accuracy: 0.7764 - val_loss: 0.5175 - val_accuracy: 0.7930\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5192 - accuracy: 0.7764 - val_loss: 0.5169 - val_accuracy: 0.7930\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5128 - accuracy: 0.7764 - val_loss: 0.5146 - val_accuracy: 0.7930\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.5181 - accuracy: 0.7764 - val_loss: 0.5188 - val_accuracy: 0.7930\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5287 - accuracy: 0.7764 - val_loss: 0.5222 - val_accuracy: 0.7930\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5186 - accuracy: 0.7764 - val_loss: 0.5158 - val_accuracy: 0.7930\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5288 - accuracy: 0.7764 - val_loss: 0.5314 - val_accuracy: 0.7930\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5264 - accuracy: 0.7764 - val_loss: 0.5168 - val_accuracy: 0.7930\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5210 - accuracy: 0.7764 - val_loss: 0.5185 - val_accuracy: 0.7930\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5140 - accuracy: 0.7764 - val_loss: 0.5196 - val_accuracy: 0.7930\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5180 - accuracy: 0.7764 - val_loss: 0.5152 - val_accuracy: 0.7930\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5161 - accuracy: 0.7764 - val_loss: 0.5219 - val_accuracy: 0.7930\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5202 - accuracy: 0.7754 - val_loss: 0.5177 - val_accuracy: 0.7930\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5231 - accuracy: 0.7764 - val_loss: 0.5184 - val_accuracy: 0.7930\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5178 - accuracy: 0.7764 - val_loss: 0.5129 - val_accuracy: 0.7930\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5198 - accuracy: 0.7764 - val_loss: 0.5230 - val_accuracy: 0.7930\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5185 - accuracy: 0.7764 - val_loss: 0.5142 - val_accuracy: 0.7930\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5178 - accuracy: 0.7764 - val_loss: 0.5155 - val_accuracy: 0.7930\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5158 - accuracy: 0.7764 - val_loss: 0.5151 - val_accuracy: 0.7930\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5129 - accuracy: 0.7764 - val_loss: 0.5143 - val_accuracy: 0.7930\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5074 - accuracy: 0.7764 - val_loss: 0.5154 - val_accuracy: 0.7930\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5149 - accuracy: 0.7764 - val_loss: 0.5149 - val_accuracy: 0.7930\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5096 - accuracy: 0.7764 - val_loss: 0.5168 - val_accuracy: 0.7930\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5095 - accuracy: 0.7764 - val_loss: 0.5174 - val_accuracy: 0.7930\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5200 - accuracy: 0.7764 - val_loss: 0.5139 - val_accuracy: 0.7930\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5152 - accuracy: 0.7764 - val_loss: 0.5182 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5182 - accuracy: 0.7930\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 3s 22ms/step - loss: 0.6044 - accuracy: 0.7061 - val_loss: 0.5258 - val_accuracy: 0.7930\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5660 - accuracy: 0.7695 - val_loss: 0.5261 - val_accuracy: 0.7930\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5500 - accuracy: 0.7744 - val_loss: 0.5244 - val_accuracy: 0.7930\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5600 - accuracy: 0.7725 - val_loss: 0.5269 - val_accuracy: 0.7930\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5522 - accuracy: 0.7754 - val_loss: 0.5261 - val_accuracy: 0.7930\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5363 - accuracy: 0.7754 - val_loss: 0.5255 - val_accuracy: 0.7930\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5472 - accuracy: 0.7764 - val_loss: 0.5279 - val_accuracy: 0.7930\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5433 - accuracy: 0.7764 - val_loss: 0.5281 - val_accuracy: 0.7930\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5447 - accuracy: 0.7754 - val_loss: 0.5286 - val_accuracy: 0.7930\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5403 - accuracy: 0.7773 - val_loss: 0.5270 - val_accuracy: 0.7930\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5450 - accuracy: 0.7764 - val_loss: 0.5272 - val_accuracy: 0.7930\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5341 - accuracy: 0.7764 - val_loss: 0.5256 - val_accuracy: 0.7930\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5468 - accuracy: 0.7764 - val_loss: 0.5260 - val_accuracy: 0.7930\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5400 - accuracy: 0.7764 - val_loss: 0.5274 - val_accuracy: 0.7930\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5364 - accuracy: 0.7764 - val_loss: 0.5246 - val_accuracy: 0.7930\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5382 - accuracy: 0.7764 - val_loss: 0.5275 - val_accuracy: 0.7930\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5324 - accuracy: 0.7764 - val_loss: 0.5234 - val_accuracy: 0.7930\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5357 - accuracy: 0.7764 - val_loss: 0.5255 - val_accuracy: 0.7930\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5230 - accuracy: 0.7764 - val_loss: 0.5238 - val_accuracy: 0.7930\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5371 - accuracy: 0.7764 - val_loss: 0.5247 - val_accuracy: 0.7930\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5385 - accuracy: 0.7764 - val_loss: 0.5261 - val_accuracy: 0.7930\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5356 - accuracy: 0.7764 - val_loss: 0.5233 - val_accuracy: 0.7930\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5362 - accuracy: 0.7764 - val_loss: 0.5277 - val_accuracy: 0.7930\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5350 - accuracy: 0.7764 - val_loss: 0.5258 - val_accuracy: 0.7930\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5369 - accuracy: 0.7764 - val_loss: 0.5251 - val_accuracy: 0.7930\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5335 - accuracy: 0.7764 - val_loss: 0.5237 - val_accuracy: 0.7930\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5328 - accuracy: 0.7764 - val_loss: 0.5225 - val_accuracy: 0.7930\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5305 - accuracy: 0.7764 - val_loss: 0.5234 - val_accuracy: 0.7930\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5365 - accuracy: 0.7764 - val_loss: 0.5265 - val_accuracy: 0.7930\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5349 - accuracy: 0.7764 - val_loss: 0.5235 - val_accuracy: 0.7930\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5362 - accuracy: 0.7764 - val_loss: 0.5225 - val_accuracy: 0.7930\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5376 - accuracy: 0.7764 - val_loss: 0.5245 - val_accuracy: 0.7930\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5286 - accuracy: 0.7764 - val_loss: 0.5239 - val_accuracy: 0.7930\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5356 - accuracy: 0.7764 - val_loss: 0.5247 - val_accuracy: 0.7930\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5351 - accuracy: 0.7764 - val_loss: 0.5208 - val_accuracy: 0.7930\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5331 - accuracy: 0.7764 - val_loss: 0.5227 - val_accuracy: 0.7930\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5279 - accuracy: 0.7764 - val_loss: 0.5208 - val_accuracy: 0.7930\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5349 - accuracy: 0.7764 - val_loss: 0.5213 - val_accuracy: 0.7930\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5336 - accuracy: 0.7764 - val_loss: 0.5215 - val_accuracy: 0.7930\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5382 - accuracy: 0.7764 - val_loss: 0.5230 - val_accuracy: 0.7930\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5346 - accuracy: 0.7764 - val_loss: 0.5226 - val_accuracy: 0.7930\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5389 - accuracy: 0.7764 - val_loss: 0.5214 - val_accuracy: 0.7930\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5294 - accuracy: 0.7764 - val_loss: 0.5195 - val_accuracy: 0.7930\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5371 - accuracy: 0.7764 - val_loss: 0.5214 - val_accuracy: 0.7930\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5331 - accuracy: 0.7764 - val_loss: 0.5200 - val_accuracy: 0.7930\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5342 - accuracy: 0.7764 - val_loss: 0.5220 - val_accuracy: 0.7930\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5300 - accuracy: 0.7764 - val_loss: 0.5202 - val_accuracy: 0.7930\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5330 - accuracy: 0.7764 - val_loss: 0.5207 - val_accuracy: 0.7930\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5325 - accuracy: 0.7764 - val_loss: 0.5211 - val_accuracy: 0.7930\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5346 - accuracy: 0.7764 - val_loss: 0.5218 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5218 - accuracy: 0.7930\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 5s 27ms/step - loss: 0.5965 - accuracy: 0.7314 - val_loss: 0.5283 - val_accuracy: 0.7930\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5751 - accuracy: 0.7764 - val_loss: 0.5263 - val_accuracy: 0.7930\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5480 - accuracy: 0.7773 - val_loss: 0.5260 - val_accuracy: 0.7930\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5464 - accuracy: 0.7764 - val_loss: 0.5283 - val_accuracy: 0.7930\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5540 - accuracy: 0.7764 - val_loss: 0.5263 - val_accuracy: 0.7930\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5417 - accuracy: 0.7764 - val_loss: 0.5287 - val_accuracy: 0.7930\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5450 - accuracy: 0.7764 - val_loss: 0.5278 - val_accuracy: 0.7930\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5393 - accuracy: 0.7764 - val_loss: 0.5312 - val_accuracy: 0.7930\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5366 - accuracy: 0.7764 - val_loss: 0.5300 - val_accuracy: 0.7930\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5371 - accuracy: 0.7764 - val_loss: 0.5310 - val_accuracy: 0.7930\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5442 - accuracy: 0.7764 - val_loss: 0.5310 - val_accuracy: 0.7930\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5385 - accuracy: 0.7764 - val_loss: 0.5300 - val_accuracy: 0.7930\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5378 - accuracy: 0.7764 - val_loss: 0.5297 - val_accuracy: 0.7930\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5340 - accuracy: 0.7764 - val_loss: 0.5274 - val_accuracy: 0.7930\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5337 - accuracy: 0.7764 - val_loss: 0.5277 - val_accuracy: 0.7930\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5362 - accuracy: 0.7764 - val_loss: 0.5293 - val_accuracy: 0.7930\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5352 - accuracy: 0.7764 - val_loss: 0.5262 - val_accuracy: 0.7930\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5335 - accuracy: 0.7764 - val_loss: 0.5291 - val_accuracy: 0.7930\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5399 - accuracy: 0.7764 - val_loss: 0.5289 - val_accuracy: 0.7930\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5360 - accuracy: 0.7764 - val_loss: 0.5266 - val_accuracy: 0.7930\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5346 - accuracy: 0.7764 - val_loss: 0.5250 - val_accuracy: 0.7930\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5290 - accuracy: 0.7764 - val_loss: 0.5257 - val_accuracy: 0.7930\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5428 - accuracy: 0.7764 - val_loss: 0.5300 - val_accuracy: 0.7930\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5425 - accuracy: 0.7764 - val_loss: 0.5251 - val_accuracy: 0.7930\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5360 - accuracy: 0.7764 - val_loss: 0.5292 - val_accuracy: 0.7930\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.5353 - accuracy: 0.7764 - val_loss: 0.5275 - val_accuracy: 0.7930\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5358 - accuracy: 0.7764 - val_loss: 0.5282 - val_accuracy: 0.7930\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5323 - accuracy: 0.7764 - val_loss: 0.5271 - val_accuracy: 0.7930\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5372 - accuracy: 0.7764 - val_loss: 0.5257 - val_accuracy: 0.7930\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5301 - accuracy: 0.7764 - val_loss: 0.5253 - val_accuracy: 0.7930\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5302 - accuracy: 0.7764 - val_loss: 0.5268 - val_accuracy: 0.7930\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5344 - accuracy: 0.7764 - val_loss: 0.5284 - val_accuracy: 0.7930\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5260 - accuracy: 0.7764 - val_loss: 0.5245 - val_accuracy: 0.7930\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5354 - accuracy: 0.7764 - val_loss: 0.5294 - val_accuracy: 0.7930\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5354 - accuracy: 0.7764 - val_loss: 0.5244 - val_accuracy: 0.7930\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5269 - accuracy: 0.7764 - val_loss: 0.5240 - val_accuracy: 0.7930\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5303 - accuracy: 0.7764 - val_loss: 0.5220 - val_accuracy: 0.7930\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5261 - accuracy: 0.7764 - val_loss: 0.5236 - val_accuracy: 0.7930\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5300 - accuracy: 0.7764 - val_loss: 0.5243 - val_accuracy: 0.7930\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5268 - accuracy: 0.7764 - val_loss: 0.5246 - val_accuracy: 0.7930\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5300 - accuracy: 0.7764 - val_loss: 0.5253 - val_accuracy: 0.7930\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5311 - accuracy: 0.7764 - val_loss: 0.5224 - val_accuracy: 0.7930\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5296 - accuracy: 0.7764 - val_loss: 0.5205 - val_accuracy: 0.7930\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5229 - accuracy: 0.7764 - val_loss: 0.5219 - val_accuracy: 0.7930\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5260 - accuracy: 0.7764 - val_loss: 0.5225 - val_accuracy: 0.7930\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5307 - accuracy: 0.7764 - val_loss: 0.5243 - val_accuracy: 0.7930\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5260 - accuracy: 0.7764 - val_loss: 0.5236 - val_accuracy: 0.7930\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.5341 - accuracy: 0.7764 - val_loss: 0.5231 - val_accuracy: 0.7930\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.5262 - accuracy: 0.7764 - val_loss: 0.5213 - val_accuracy: 0.7930\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.5275 - accuracy: 0.7764 - val_loss: 0.5245 - val_accuracy: 0.7930\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5245 - accuracy: 0.7930\n",
            "        frontal   central  parietal  occipital\n",
            "theta  0.792969  0.792969  0.792969   0.792969\n",
            "alpha  0.792969  0.792969  0.792969   0.792969\n",
            "beta   0.792969  0.792969  0.792969   0.792969\n",
            "gamma  0.792969  0.792969  0.792969   0.792969\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oY9uqQzbv46q"
      },
      "outputs": [],
      "source": [
        "# print the confusion matrix which gives the highest accuracy\n",
        "print_conf(\"theta\",\"parietal\",\"arousal\",\"svm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHUBype4mFY6"
      },
      "outputs": [],
      "source": [
        "print_accuracy('valence', 'svm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bv3oLNIVGCSf"
      },
      "outputs": [],
      "source": [
        "print_conf(\"gamma\",\"central\",\"valence\",\"svm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IoKgtLNEpU-v"
      },
      "outputs": [],
      "source": [
        "print_accuracy('HAHV', 'ab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BcqO8QBLHR7q"
      },
      "outputs": [],
      "source": [
        "print_conf(\"gamma\",\"occipital\",\"arousal\",\"ab\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1za3TrVphgH"
      },
      "outputs": [],
      "source": [
        "print_accuracy('valence', 'ab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1DPjYGhArgcr"
      },
      "outputs": [],
      "source": [
        "print_accuracy('HAHV', 'xgb')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYrfmtLwrmES"
      },
      "outputs": [],
      "source": [
        "print_accuracy('valence', 'xgb')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_wzHU40YhWY"
      },
      "outputs": [],
      "source": [
        "print_conf(\"beta\",\"central\",\"valence\",\"xgb\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3qH1vs2J5rC"
      },
      "outputs": [],
      "source": [
        "print_accuracy('HAHV', 'knn')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x84JhQCIKciv"
      },
      "outputs": [],
      "source": [
        "print_accuracy('LALV', 'knn')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7XXLSSWWl9kI"
      },
      "outputs": [],
      "source": [
        "print_accuracy('HALV', 'knn')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4WnM3ismDzw"
      },
      "outputs": [],
      "source": [
        "print_accuracy('LAHV', 'knn')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXS8oiqJKknT"
      },
      "outputs": [],
      "source": [
        "print_accuracy('HAHV', 'dtree')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPn1ljyNKtr4"
      },
      "outputs": [],
      "source": [
        "print_accuracy('LALV', 'dtree')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zS_EF8dRKyLm"
      },
      "outputs": [],
      "source": [
        "print_accuracy('HAHV', 'rf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "luDd1AY6mjqs"
      },
      "outputs": [],
      "source": [
        "print_accuracy('LAHV', 'rf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNTGFHQOK14l"
      },
      "outputs": [],
      "source": [
        "print_accuracy('HALV', 'rf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhGLn0G4_l8E"
      },
      "outputs": [],
      "source": [
        "print_accuracy('LALV', 'rf')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy('HAHV', 'cnn')"
      ],
      "metadata": {
        "id": "lkL0I6x7PY-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MkmagqFfK54a"
      },
      "outputs": [],
      "source": [
        "print_accuracy('HALV', 'cnn')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uV3gnYCKK-cA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02_ynnQ1LEoz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuwCpDS1LHAx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tAvwS8OmOkX6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIwlFJ7nOyFX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBw1c8r9O6s5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mBzYOJwO-Tc"
      },
      "outputs": [],
      "source": [
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_tYtr1vPEwA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yz0L94FJPKCx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPkBIcPtPTXf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "al5LA0spYBqU"
      },
      "outputs": [],
      "source": [
        "# print_conf(\"gamma\",\"frontal\",\"arousal\",\"cb\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LB1NnMQQcTD"
      },
      "outputs": [],
      "source": [
        "print_accuracy('HAHV', 'cb')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}